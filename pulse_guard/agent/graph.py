"""
LangGraph ä»£ç å®¡æŸ¥ Agent å®ç°ã€‚
"""

import asyncio
import logging
from typing import Any, Dict, List, Optional, TypedDict, Union

from langchain_core.messages import AIMessage, HumanMessage
from langgraph.graph import END, StateGraph

from pulse_guard.agent.data_validator import data_validator
from pulse_guard.llm.client import get_llm
from pulse_guard.models.review import (
    CodeIssue,
    FileReview,
    IssueCategory,
    PRReview,
    SeverityLevel,
)
from pulse_guard.platforms import get_platform_provider

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)


# å®šä¹‰ Agent çŠ¶æ€ç±»å‹
class AgentState(TypedDict):
    """Agent çŠ¶æ€"""

    messages: List[Union[AIMessage, HumanMessage]]
    pr_info: Dict[str, Any]
    files: List[Dict[str, Any]]
    file_contents: Dict[str, str]
    current_file_index: int
    file_reviews: List[Dict[str, Any]]
    overall_summary: Optional[str]
    enhanced_analysis: Optional[Dict[str, Any]]
    db_record_id: Optional[int]


# ä»£ç æ–‡ä»¶æ‰©å±•å
CODE_EXTENSIONS = {
    ".py",
    ".vue",
    ".js",
    ".ts",
    ".jsx",
    ".tsx",
    ".java",
    ".cpp",
    ".c",
    ".h",
    ".hpp",
    ".go",
    ".rs",
    ".php",
    ".rb",
    ".swift",
    ".kt",
    ".scala",
    ".cs",
    ".vb",
    ".sql",
    ".yaml",
    ".yml",
    ".xml",
    ".html",
    ".css",
    ".scss",
    ".less",
    ".sh",
    ".bash",
    ".ps1",
    ".bat",
    ".dockerfile",
    ".makefile",
    ".md",
    ".txt",
    ".cfg",
    ".conf",
    ".ini",
    ".toml",
    ".properties",
    ".gradle",
    ".maven",
    ".sbt",
    ".cmake",
    ".r",
    ".m",
    ".pl",
    ".lua",
}

# è·³è¿‡çš„æ–‡ä»¶æ¨¡å¼
SKIP_PATTERNS = [
    r".*\.(png|jpg|jpeg|gif|svg|ico|bmp|tiff|webp)$",  # å›¾ç‰‡
    r".*\.(pdf|doc|docx|xls|xlsx|ppt|pptx)$",  # æ–‡æ¡£
    r".*\.(zip|tar|gz|rar|7z|bz2)$",  # å‹ç¼©åŒ…
    r".*\.(mp4|avi|mov|wmv|flv|mp3|wav|ogg)$",  # åª’ä½“æ–‡ä»¶
    r"(^|.*/)node_modules/.*",  # ä¾èµ–ç›®å½•
    r"(^|.*/)\.git/.*",  # Gitç›®å½•
    r".*\.min\.(js|css)$",  # å‹ç¼©æ–‡ä»¶
    r".*\.(lock|log)$",  # é”æ–‡ä»¶å’Œæ—¥å¿—
]


def _is_code_file(filename: str) -> bool:
    """åˆ¤æ–­æ˜¯å¦ä¸ºä»£ç æ–‡ä»¶"""
    import re

    # æ£€æŸ¥æ˜¯å¦åŒ¹é…è·³è¿‡æ¨¡å¼ï¼ˆä½¿ç”¨ search è€Œä¸æ˜¯ match æ¥åŒ¹é…è·¯å¾„ä¸­çš„ä»»ä½•ä½ç½®ï¼‰
    for pattern in SKIP_PATTERNS:
        if re.search(pattern, filename, re.IGNORECASE):
            return False

    # ç‰¹æ®Šæ–‡ä»¶åæ£€æŸ¥ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
    code_filenames = {
        "makefile",
        "dockerfile",
        "rakefile",
        "gemfile",
        "podfile",
        "requirements.txt",
        "package-lock.json",
        "yarn.lock",
        "composer.lock",
        ".gitignore",
        ".gitattributes",
        ".dockerignore",
        ".eslintrc",
        ".prettierrc",
        ".babelrc",
        ".editorconfig",
        ".env",
        ".env.example",
        ".env.local",
        "license",
        "changelog",
        "contributing",
        "authors",
        "maintainers",
    }

    # æ£€æŸ¥å®Œæ•´æ–‡ä»¶å
    if filename.lower() in code_filenames:
        return True

    # æ£€æŸ¥æ–‡ä»¶åï¼ˆä¸å«è·¯å¾„ï¼‰
    basename = filename.split("/")[-1].lower()
    if basename in code_filenames:
        return True

    # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
    if "." in filename and not filename.startswith("."):
        ext = "." + filename.split(".")[-1].lower()
        return ext in CODE_EXTENSIONS

    return False


def fetch_pr_and_code_files(state: AgentState) -> AgentState:
    """è·å–PRä¿¡æ¯å’Œä»£ç æ–‡ä»¶å†…å®¹ï¼ˆåˆå¹¶åŸæ¥çš„analyze_prå’Œget_file_contentsï¼‰"""
    pr_info = state["pr_info"]

    # éªŒè¯å’Œæ¸…ç†PRä¿¡æ¯
    validated_pr_info = data_validator.validate_pr_info(pr_info)
    platform = validated_pr_info.get("platform", "github")

    # è·å–å¹³å°æä¾›è€…
    provider = get_platform_provider(platform)

    # è·å– PR è¯¦ç»†ä¿¡æ¯
    pr_details = provider.get_pr_info(
        validated_pr_info["repo"], validated_pr_info["number"]
    )

    # éªŒè¯å’Œåˆå¹¶PRè¯¦ç»†ä¿¡æ¯
    merged_pr_info = data_validator.validate_pr_info(
        {**validated_pr_info, **pr_details}
    )

    # è·å– PR ä¿®æ”¹çš„æ–‡ä»¶åˆ—è¡¨
    all_files = provider.get_pr_files(
        validated_pr_info["repo"], validated_pr_info["number"]
    )

    # éªŒè¯å’Œæ¸…ç†æ–‡ä»¶ä¿¡æ¯
    validated_files = data_validator.validate_files_info(all_files)

    # è¿‡æ»¤å‡ºä»£ç æ–‡ä»¶
    code_files = [f for f in validated_files if _is_code_file(f["filename"])]

    logger.info(
        f"æ€»æ–‡ä»¶æ•°: {len(all_files)}, éªŒè¯åæ–‡ä»¶æ•°: {len(validated_files)}, ä»£ç æ–‡ä»¶æ•°: {len(code_files)}"
    )

    # è·å–æ‰€æœ‰ä»£ç æ–‡ä»¶çš„å†…å®¹
    file_contents = {}
    for file in code_files:
        if file["status"] != "removed":
            try:
                content = provider.get_file_content(
                    merged_pr_info["repo_full_name"],
                    file["filename"],
                    merged_pr_info["head_sha"],
                )
                file_contents[file["filename"]] = content
            except Exception as e:
                # å¦‚æœè·å–æ–‡ä»¶å†…å®¹å¤±è´¥ï¼Œè®°å½•é”™è¯¯
                file_contents[file["filename"]] = (
                    f"Error fetching file content: {str(e)}"
                )
                logger.warning(f"è·å–æ–‡ä»¶å†…å®¹å¤±è´¥ {file['filename']}: {e}")

    # å°†æ–‡ä»¶å†…å®¹åˆå¹¶åˆ°æ–‡ä»¶ä¿¡æ¯ä¸­
    enhanced_files = []
    for file in code_files:
        enhanced_file = {**file, "content": file_contents.get(file["filename"], "")}
        enhanced_files.append(enhanced_file)

    # æ›´æ–°çŠ¶æ€
    return {
        **state,
        "pr_info": merged_pr_info,
        "files": enhanced_files,
        "file_contents": file_contents,
        "current_file_index": 0,
        "file_reviews": [],
    }


async def intelligent_code_review(state: AgentState) -> AgentState:
    """æ™ºèƒ½ä»£ç å®¡æŸ¥ - æŒ‰æ–‡ä»¶å¹¶å‘è°ƒç”¨LLM"""
    pr_info = state["pr_info"]
    files = state["files"]

    if not files:
        logger.warning("æ²¡æœ‰ä»£ç æ–‡ä»¶éœ€è¦å®¡æŸ¥")
        return {
            **state,
            "file_reviews": [],
            "overall_summary": "æ²¡æœ‰ä»£ç æ–‡ä»¶éœ€è¦å®¡æŸ¥",
            "enhanced_analysis": {
                "overall_score": 100,
                "code_quality_score": 100,
                "security_score": 100,
                "business_score": 100,
                "file_results": [],
                "summary": "æ²¡æœ‰ä»£ç æ–‡ä»¶éœ€è¦å®¡æŸ¥",
            },
        }

    logger.info(f"å¼€å§‹å¹¶å‘å®¡æŸ¥ {len(files)} ä¸ªä»£ç æ–‡ä»¶")

    # å¹¶å‘å®¡æŸ¥æ¯ä¸ªæ–‡ä»¶
    file_reviews = []
    try:
        logger.info(f"ä½¿ç”¨ asyncio.gather å¹¶å‘å¤„ç† {len(files)} ä¸ªæ–‡ä»¶")

        # åˆ›å»ºæ‰€æœ‰æ–‡ä»¶å®¡æŸ¥ä»»åŠ¡
        tasks = []
        for file in files:
            task = _review_single_file_async(file, pr_info)
            tasks.append(task)

        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        results = await asyncio.gather(*tasks, return_exceptions=True)

        # å¤„ç†ç»“æœ
        for i, (file, result) in enumerate(zip(files, results)):
            if isinstance(result, Exception):
                logger.error(f"æ–‡ä»¶ {file['filename']} å®¡æŸ¥å¼‚å¸¸: {result}")
                # æ·»åŠ å¤±è´¥çš„é»˜è®¤ç»“æœ
                file_reviews.append(
                    {
                        "filename": file["filename"],
                        "score": 70,
                        "issues": [
                            {
                                "type": "error",
                                "title": "å®¡æŸ¥å¤±è´¥",
                                "description": str(result),
                            }
                        ],
                        "positive_points": [],
                        "summary": f"å®¡æŸ¥å¤±è´¥: {str(result)}",
                    }
                )
            else:
                file_reviews.append(result)
                logger.info(f"æ–‡ä»¶ {file['filename']} å®¡æŸ¥å®Œæˆ")

        # è®¡ç®—æ€»ä½“è¯„åˆ†
        overall_result = _calculate_overall_scores(file_reviews)

        logger.info(f"å¹¶å‘å®¡æŸ¥å®Œæˆï¼Œæ€»ä½“è¯„åˆ†: {overall_result['overall_score']}")

        return {
            **state,
            "file_reviews": file_reviews,
            "overall_summary": overall_result.get("summary", "å¹¶å‘å®¡æŸ¥å®Œæˆ"),
            "enhanced_analysis": {
                "overall_score": overall_result.get("overall_score", 80),
                "code_quality_score": overall_result.get("code_quality_score", 80),
                "security_score": overall_result.get("security_score", 80),
                "business_score": overall_result.get("business_score", 80),
                "file_results": file_reviews,
                "summary": overall_result.get("summary", "å¹¶å‘å®¡æŸ¥å®Œæˆ"),
                "standards_passed": overall_result.get("standards_passed", 0),
                "standards_failed": overall_result.get("standards_failed", 0),
                "standards_total": overall_result.get("standards_total", 0),
            },
        }

    except Exception as e:
        logger.error(f"å¹¶å‘å®¡æŸ¥å¤±è´¥: {e}")
        # é™çº§åˆ°ç®€å•å®¡æŸ¥
        return _fallback_simple_review(state)


def generate_summary(state: AgentState) -> AgentState:
    """ç”Ÿæˆæ€»ä½“è¯„ä»·"""
    file_reviews = state["file_reviews"]
    enhanced_analysis = state.get("enhanced_analysis")

    # å¦‚æœæœ‰å¢å¼ºåˆ†æç»“æœï¼Œä¼˜å…ˆä½¿ç”¨
    if enhanced_analysis:
        return {**state, "overall_summary": enhanced_analysis["summary"]}

    # å¦‚æœæ²¡æœ‰æ–‡ä»¶å®¡æŸ¥ç»“æœï¼Œè¿”å›é»˜è®¤æ€»ç»“
    if not file_reviews:
        return {**state, "overall_summary": "æ²¡æœ‰æ‰¾åˆ°éœ€è¦å®¡æŸ¥çš„æ–‡ä»¶ã€‚"}

    # æ„å»ºæ–‡ä»¶å®¡æŸ¥æ‘˜è¦
    file_reviews_text = ""
    for review in file_reviews:
        filename = review["filename"]
        summary = review["summary"]
        issues_count = len(review["issues"])

        file_reviews_text += f"## {filename}\n"
        file_reviews_text += f"- æ‘˜è¦: {summary}\n"
        file_reviews_text += f"- é—®é¢˜æ•°: {issues_count}\n"

        if issues_count > 0:
            file_reviews_text += "- é—®é¢˜åˆ—è¡¨:\n"
            for issue in review["issues"]:
                file_reviews_text += f"  - [{issue['severity']}] {issue['title']}\n"

        file_reviews_text += "\n"

    # ä½¿ç”¨ LLM ç”Ÿæˆæ€»ä½“è¯„ä»·
    llm = get_llm()

    prompt = f"""
è¯·æ ¹æ®ä»¥ä¸‹å„æ–‡ä»¶çš„ä»£ç å®¡æŸ¥ç»“æœï¼Œç”Ÿæˆä¸€ä¸ªæ€»ä½“è¯„ä»·:

{file_reviews_text}

è¯·åœ¨æ€»ç»“ä¸­åŒ…æ‹¬:
1. PR çš„æ•´ä½“è´¨é‡è¯„ä»·ï¼Œä» 0 åˆ° 10 åˆ†ç»™ PR è¯„åˆ†
2. ä¸»è¦é—®é¢˜å’Œæ¨¡å¼
3. å…³é”®æ”¹è¿›å»ºè®®
4. ç§¯æçš„åé¦ˆå’Œé¼“åŠ±

ä½ çš„æ€»ç»“å°†ä½œä¸º PR è¯„è®ºçš„å¼€å¤´éƒ¨åˆ†ï¼Œåº”è¯¥å‹å¥½ã€ä¸“ä¸šä¸”æœ‰å»ºè®¾æ€§ã€‚

è¯·ä½¿ç”¨ä¸­æ–‡å›å¤ã€‚
"""

    # è·å– LLM å“åº”
    response = llm.invoke(prompt)
    overall_summary = response.content

    # æ›´æ–°çŠ¶æ€
    return {**state, "overall_summary": overall_summary}


def post_review_comment(state: AgentState) -> AgentState:
    """å‘å¸ƒå®¡æŸ¥è¯„è®ºå¹¶ä¿å­˜åˆ°æ•°æ®åº“"""
    pr_info = state["pr_info"]
    platform = pr_info.get("platform", "github")
    file_reviews = state["file_reviews"]
    overall_summary = state["overall_summary"]
    enhanced_analysis = state.get("enhanced_analysis")

    # é¦–å…ˆä¿å­˜å®¡æŸ¥ç»“æœåˆ°æ•°æ®åº“
    try:
        from pulse_guard.database import DatabaseManager

        db_record_id = DatabaseManager.save_complete_review_result(
            repo_full_name=pr_info.get("repo_full_name", pr_info.get("repo", "")),
            pr_number=pr_info.get("number", 0),
            pr_title=pr_info.get("title", ""),
            pr_description=pr_info.get("description", ""),
            pr_author=pr_info.get("author", ""),
            platform=platform,
            review_result={
                "enhanced_analysis": enhanced_analysis,
                "file_reviews": file_reviews,
            },
        )
        logger.info(f"å®¡æŸ¥ç»“æœå·²ä¿å­˜åˆ°æ•°æ®åº“ï¼Œè®°å½•ID: {db_record_id}")

        # æ›´æ–°çŠ¶æ€ä¸­çš„æ•°æ®åº“è®°å½•ID
        state = {**state, "db_record_id": db_record_id}

    except Exception as e:
        logger.error(f"ä¿å­˜å®¡æŸ¥ç»“æœåˆ°æ•°æ®åº“å¤±è´¥: {e}")
        # ç»§ç»­æ‰§è¡Œï¼Œä¸å› ä¸ºæ•°æ®åº“ä¿å­˜å¤±è´¥è€Œä¸­æ–­è¯„è®ºå‘å¸ƒ

    # åˆ›å»ºå¢å¼ºçš„è¯„è®ºå†…å®¹
    comment_parts = []

    # æ·»åŠ å¢å¼ºåˆ†æç»“æœ
    if enhanced_analysis:
        comment_parts.append("# ğŸ” ä»£ç å®¡æŸ¥æŠ¥å‘Š")
        comment_parts.append("")
        comment_parts.append("## ğŸ“Š è¯„åˆ†æ¦‚è§ˆ")
        comment_parts.append(
            f"- **æ€»ä½“è¯„åˆ†**: {enhanced_analysis['overall_score']:.1f}/100"
        )
        comment_parts.append(
            f"- **ä¸šåŠ¡é€»è¾‘**: {enhanced_analysis['business_score']:.1f}/100"
        )
        comment_parts.append(
            f"- **ä»£ç è´¨é‡**: {enhanced_analysis['code_quality_score']:.1f}/100"
        )
        comment_parts.append(
            f"- **å®‰å…¨æ€§**: {enhanced_analysis['security_score']:.1f}/100"
        )
        comment_parts.append(
            f"- **è§„èŒƒé€šè¿‡ç‡**: {enhanced_analysis['standards_passed']}/{enhanced_analysis['standards_total']}"
        )
        comment_parts.append("")
        comment_parts.append("## ğŸ“ æ€»ä½“è¯„ä»·")
        comment_parts.append(enhanced_analysis["summary"])
        comment_parts.append("")

        # æ·»åŠ æ–‡ä»¶å½±å“åˆ†æ
        if enhanced_analysis.get("file_results"):
            comment_parts.append("## ğŸ“ æ–‡ä»¶å½±å“åˆ†æ")
            for fa in enhanced_analysis["file_results"]:
                # å®‰å…¨åœ°è·å–å½±å“çº§åˆ«ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼
                impact_level = fa.get("impact_level", fa.get("type", "medium"))
                impact_emoji = {
                    "low": "ğŸŸ¢",
                    "medium": "ğŸŸ¡",
                    "high": "ğŸŸ ",
                    "critical": "ğŸ”´",
                }.get(impact_level, "âšª")

                comment_parts.append(f"### {impact_emoji} `{fa['filename']}`")
                comment_parts.append(f"- **å½±å“çº§åˆ«**: {impact_level}")
                comment_parts.append(
                    f"- **ä»£ç è´¨é‡**: {fa.get('code_quality_score', 80):.1f}/100"
                )
                comment_parts.append(
                    f"- **å®‰å…¨è¯„åˆ†**: {fa.get('security_score', 80):.1f}/100"
                )
                comment_parts.append(f"- **é—®é¢˜æ•°é‡**: {len(fa.get('issues', []))}")
                comment_parts.append(
                    f"- **ä¸šåŠ¡å½±å“**: {fa.get('summary', fa.get('business_impact', 'æ— ç‰¹æ®Šå½±å“'))}"
                )
                comment_parts.append("")

    # åˆ›å»º PR å®¡æŸ¥ç»“æœ - å®‰å…¨åœ°åˆ›å»º CodeIssue å¯¹è±¡
    def _safe_create_code_issue(issue_dict: Dict[str, Any]) -> CodeIssue:
        """å®‰å…¨åœ°åˆ›å»º CodeIssue å¯¹è±¡"""
        try:
            # ç¡®ä¿å¿…éœ€å­—æ®µå­˜åœ¨
            severity_str = issue_dict.get("severity", issue_dict.get("type", "info"))
            category_str = issue_dict.get("category", "other")

            # è½¬æ¢ä¸ºæšä¸¾å€¼
            try:
                severity = SeverityLevel(severity_str.lower())
            except ValueError:
                severity = SeverityLevel.INFO

            try:
                category = IssueCategory(category_str.lower())
            except ValueError:
                category = IssueCategory.OTHER

            return CodeIssue(
                title=issue_dict.get("title", "æœªçŸ¥é—®é¢˜"),
                description=issue_dict.get("description", ""),
                severity=severity,
                category=category,
                line_start=issue_dict.get("line", issue_dict.get("line_start")),
                line_end=issue_dict.get("line", issue_dict.get("line_end")),
                suggestion=issue_dict.get("suggestion", ""),
            )
        except Exception as e:
            logger.warning(f"åˆ›å»º CodeIssue å¤±è´¥: {e}, ä½¿ç”¨é»˜è®¤å€¼")
            return CodeIssue(
                title=issue_dict.get("title", "è§£æå¤±è´¥çš„é—®é¢˜"),
                description=str(issue_dict),
                severity=SeverityLevel.INFO,
                category=IssueCategory.OTHER,
            )

    pr_review = PRReview(
        pr_number=pr_info["number"],
        repo_full_name=pr_info["repo_full_name"],
        overall_summary=overall_summary,
        file_reviews=[
            FileReview(
                filename=review["filename"],
                summary=review["summary"],
                issues=[
                    _safe_create_code_issue(issue) for issue in review.get("issues", [])
                ],
            )
            for review in file_reviews
        ],
    )

    # ç”Ÿæˆå®Œæ•´çš„è¯„è®ºå†…å®¹ï¼ˆç°åœ¨å¯ä»¥åˆ†æ‰¹å‘é€ï¼‰
    if comment_parts:
        comment_text = "\n".join(comment_parts)
        # æ·»åŠ å®Œæ•´çš„è¯¦ç»†å®¡æŸ¥ç»“æœ
        comment_text += "\n\n" + pr_review.format_comment()
    else:
        comment_text = pr_review.format_comment()

    # è·å–å¹³å°æä¾›è€…å¹¶å‘å¸ƒè¯„è®º
    provider = get_platform_provider(platform)

    try:
        # ä½¿ç”¨åˆ†æ‰¹è¯„è®ºåŠŸèƒ½ï¼Œæ ¹æ®å¹³å°è®¾ç½®ä¸åŒçš„é•¿åº¦é™åˆ¶
        max_length = 4000  # é»˜è®¤é™åˆ¶
        if platform == "gitee":
            max_length = 3000  # Gitee å¯èƒ½é™åˆ¶æ›´ä¸¥æ ¼
        elif platform == "github":
            max_length = 8000  # GitHub é™åˆ¶ç›¸å¯¹å®½æ¾

        results = provider.post_pr_comments_batch(
            pr_info["repo_full_name"],
            pr_info["number"],
            comment_text,
            max_length=max_length,
        )

        # ç»Ÿè®¡å‘å¸ƒç»“æœ
        success_count = sum(1 for r in results if "error" not in r)
        total_count = len(results)

        if success_count == total_count:
            print(f"âœ… å·²å‘å¸ƒå®¡æŸ¥è¯„è®ºåˆ° PR #{pr_info['number']} (å…± {total_count} æ¡)")
        else:
            print(
                f"âš ï¸ éƒ¨åˆ†è¯„è®ºå‘å¸ƒæˆåŠŸ: {success_count}/{total_count} æ¡åˆ° PR #{pr_info['number']}"
            )

    except Exception as e:
        print(f"âŒ å‘å¸ƒè¯„è®ºå¤±è´¥: {str(e)}")
        # å¦‚æœåˆ†æ‰¹å‘å¸ƒå¤±è´¥ï¼Œå°è¯•å‘å¸ƒç®€åŒ–ç‰ˆæœ¬
        try:
            simplified_comment = _create_fallback_comment(
                file_reviews, enhanced_analysis
            )
            provider.post_pr_comment(
                pr_info["repo_full_name"], pr_info["number"], simplified_comment
            )
            print(f"âœ… å·²å‘å¸ƒç®€åŒ–è¯„è®ºåˆ° PR #{pr_info['number']}")
        except Exception as fallback_error:
            print(f"âŒ ç®€åŒ–è¯„è®ºä¹Ÿå‘å¸ƒå¤±è´¥: {str(fallback_error)}")

    # æ›´æ–°çŠ¶æ€
    return {**state, "comment": comment_text}


def _format_simplified_comment(
    pr_review: PRReview, file_reviews: List[Dict[str, Any]]
) -> str:
    """æ ¼å¼åŒ–ç®€åŒ–çš„è¯„è®ºå†…å®¹ï¼Œå‡å°‘é•¿åº¦"""
    comment_parts = []

    # æ·»åŠ ç®€åŒ–çš„æ€»ä½“è¯„ä»·
    if pr_review.overall_summary:
        comment_parts.append("## ğŸ“‹ å®¡æŸ¥æ€»ç»“")
        # é™åˆ¶æ€»ç»“é•¿åº¦
        summary = pr_review.overall_summary
        if len(summary) > 500:
            summary = summary[:500] + "..."
        comment_parts.append(summary)
        comment_parts.append("")

    # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
    total_issues = sum(len(review.get("issues", [])) for review in file_reviews)
    critical_issues = sum(
        1
        for review in file_reviews
        for issue in review.get("issues", [])
        if issue.get("severity") == "critical"
    )

    comment_parts.append("## ğŸ“Š å®¡æŸ¥ç»Ÿè®¡")
    comment_parts.append(f"- ğŸ“ å®¡æŸ¥æ–‡ä»¶: **{len(file_reviews)}** ä¸ª")
    comment_parts.append(f"- ğŸ” å‘ç°é—®é¢˜: **{total_issues}** ä¸ª")
    if critical_issues > 0:
        comment_parts.append(f"- ğŸš¨ ä¸¥é‡é—®é¢˜: **{critical_issues}** ä¸ª")
    comment_parts.append("")

    # åªæ˜¾ç¤ºæœ‰é—®é¢˜çš„æ–‡ä»¶ï¼Œå¹¶é™åˆ¶æ˜¾ç¤ºæ•°é‡
    files_with_issues = [review for review in file_reviews if review.get("issues")]
    if files_with_issues:
        comment_parts.append("## âš ï¸ éœ€è¦å…³æ³¨çš„æ–‡ä»¶")

        # æœ€å¤šæ˜¾ç¤º5ä¸ªæœ‰é—®é¢˜çš„æ–‡ä»¶
        for review in files_with_issues[:5]:
            filename = review["filename"]
            issues = review.get("issues", [])
            issue_count = len(issues)

            # ç»Ÿè®¡é—®é¢˜ä¸¥é‡ç¨‹åº¦
            critical_count = sum(
                1 for issue in issues if issue.get("severity") == "critical"
            )
            error_count = sum(1 for issue in issues if issue.get("severity") == "error")

            severity_info = []
            if critical_count > 0:
                severity_info.append(f"ğŸš¨{critical_count}")
            if error_count > 0:
                severity_info.append(f"âŒ{error_count}")

            severity_text = f" ({', '.join(severity_info)})" if severity_info else ""

            comment_parts.append(f"### `{filename}`")
            comment_parts.append(f"- é—®é¢˜æ•°é‡: **{issue_count}**{severity_text}")

            # åªæ˜¾ç¤ºæœ€ä¸¥é‡çš„é—®é¢˜
            if issues:
                # æŒ‰ä¸¥é‡ç¨‹åº¦æ’åº
                severity_order = {"critical": 0, "error": 1, "warning": 2, "info": 3}
                sorted_issues = sorted(
                    issues,
                    key=lambda x: severity_order.get(x.get("severity", "info"), 3),
                )

                top_issue = sorted_issues[0]
                comment_parts.append(
                    f"- ä¸»è¦é—®é¢˜: {top_issue.get('title', 'æœªçŸ¥é—®é¢˜')}"
                )

            comment_parts.append("")

        # å¦‚æœæœ‰æ›´å¤šæ–‡ä»¶ï¼Œæ˜¾ç¤ºæç¤º
        if len(files_with_issues) > 5:
            remaining = len(files_with_issues) - 5
            comment_parts.append(
                f"*è¿˜æœ‰ {remaining} ä¸ªæ–‡ä»¶å­˜åœ¨é—®é¢˜ï¼Œè¯¦æƒ…è¯·æŸ¥çœ‹å®Œæ•´æŠ¥å‘Š*"
            )
            comment_parts.append("")

    # æ·»åŠ ç®€åŒ–çš„å»ºè®®
    comment_parts.append("## ğŸ’¡ æ”¹è¿›å»ºè®®")
    if critical_issues > 0:
        comment_parts.append("- ğŸš¨ è¯·ä¼˜å…ˆä¿®å¤ä¸¥é‡é—®é¢˜")
    if total_issues > 10:
        comment_parts.append("- ğŸ“ å»ºè®®åˆ†æ‰¹ä¿®å¤é—®é¢˜ï¼Œé¿å…ä¸€æ¬¡æ€§ä¿®æ”¹è¿‡å¤š")
    comment_parts.append("- ğŸ” è¯¦ç»†åˆ†ææŠ¥å‘Šå¯é€šè¿‡ API æ¥å£è·å–")

    return "\n".join(comment_parts)


def _create_fallback_comment(
    file_reviews: List[Dict[str, Any]], enhanced_analysis: Dict[str, Any] = None
) -> str:
    """åˆ›å»ºæç®€çš„å¤‡ç”¨è¯„è®ºï¼Œç¡®ä¿èƒ½å¤Ÿå‘å¸ƒ"""
    parts = []

    # åŸºæœ¬ç»Ÿè®¡
    total_files = len(file_reviews)
    total_issues = sum(len(review.get("issues", [])) for review in file_reviews)
    critical_issues = sum(
        1
        for review in file_reviews
        for issue in review.get("issues", [])
        if issue.get("severity") == "critical"
    )

    parts.append("# ğŸ” ä»£ç å®¡æŸ¥å®Œæˆ")
    parts.append("")
    parts.append(f"ğŸ“Š **ç»Ÿè®¡**: {total_files} ä¸ªæ–‡ä»¶ï¼Œ{total_issues} ä¸ªé—®é¢˜")

    if critical_issues > 0:
        parts.append(f"ğŸš¨ **ä¸¥é‡é—®é¢˜**: {critical_issues} ä¸ªï¼Œè¯·ä¼˜å…ˆå¤„ç†")

    if enhanced_analysis:
        score = enhanced_analysis.get("overall_score", 80)
        parts.append(f"ğŸ“ˆ **æ€»ä½“è¯„åˆ†**: {score:.1f}/100")

    parts.append("")
    parts.append("ğŸ’¡ è¯¦ç»†æŠ¥å‘Šè¯·æŸ¥çœ‹å®Œæ•´åˆ†ææˆ–è”ç³»ç®¡ç†å‘˜")

    return "\n".join(parts)


# æ„å»º LangGraph
def build_code_review_graph():
    """æ„å»ºç®€åŒ–çš„ä»£ç å®¡æŸ¥ LangGraph"""
    # åˆ›å»ºå›¾
    workflow = StateGraph(AgentState)

    # æ·»åŠ èŠ‚ç‚¹ - ç®€åŒ–çš„æµç¨‹
    workflow.add_node("fetch_pr_and_code_files", fetch_pr_and_code_files)
    workflow.add_node("intelligent_code_review", intelligent_code_review)
    workflow.add_node("post_review_comment", post_review_comment)

    # æ·»åŠ è¾¹ - ç®€åŒ–çš„æµç¨‹
    workflow.add_edge("fetch_pr_and_code_files", "intelligent_code_review")
    workflow.add_edge("intelligent_code_review", "post_review_comment")
    workflow.add_edge("post_review_comment", END)

    # è®¾ç½®å…¥å£ç‚¹
    workflow.set_entry_point("fetch_pr_and_code_files")

    # ç¼–è¯‘å›¾
    return workflow.compile()


# è¿è¡Œä»£ç å®¡æŸ¥
async def _review_single_file_async(
    file: Dict[str, Any], pr_info: Dict[str, Any]
) -> Dict[str, Any]:
    """å¼‚æ­¥å®¡æŸ¥å•ä¸ªæ–‡ä»¶"""
    try:
        llm = get_llm()

        # æ„å»ºå•æ–‡ä»¶å®¡æŸ¥æç¤º
        prompt = _build_single_file_review_prompt(file, pr_info)

        # å¼‚æ­¥è°ƒç”¨LLM
        response = await llm.ainvoke(prompt)
        review_content = (
            response.content if hasattr(response, "content") else str(response)
        )

        # è§£æå•æ–‡ä»¶å®¡æŸ¥ç»“æœ
        file_review = _parse_single_file_response(review_content, file)

        return file_review

    except Exception as e:
        logger.error(f"å•æ–‡ä»¶å®¡æŸ¥å¤±è´¥ {file.get('filename', 'unknown')}: {e}")
        return {
            "filename": file.get("filename", "unknown"),
            "score": 70,
            "issues": [{"type": "error", "title": "å®¡æŸ¥å¼‚å¸¸", "description": str(e)}],
            "positive_points": [],
            "summary": f"å®¡æŸ¥å¼‚å¸¸: {str(e)}",
        }


def _review_single_file(
    file: Dict[str, Any], pr_info: Dict[str, Any]
) -> Dict[str, Any]:
    """å®¡æŸ¥å•ä¸ªæ–‡ä»¶ - ä¿ç•™åŒæ­¥ç‰ˆæœ¬ç”¨äºå‘åå…¼å®¹"""
    try:
        llm = get_llm()

        # æ„å»ºå•æ–‡ä»¶å®¡æŸ¥æç¤º
        prompt = _build_single_file_review_prompt(file, pr_info)

        # è°ƒç”¨LLM
        response = llm.invoke(prompt)
        review_content = (
            response.content if hasattr(response, "content") else str(response)
        )

        # è§£æå•æ–‡ä»¶å®¡æŸ¥ç»“æœ
        file_review = _parse_single_file_response(review_content, file)

        return file_review

    except Exception as e:
        logger.error(f"å•æ–‡ä»¶å®¡æŸ¥å¤±è´¥ {file.get('filename', 'unknown')}: {e}")
        return {
            "filename": file.get("filename", "unknown"),
            "score": 70,
            "issues": [{"type": "error", "title": "å®¡æŸ¥å¼‚å¸¸", "description": str(e)}],
            "positive_points": [],
            "summary": f"å®¡æŸ¥å¼‚å¸¸: {str(e)}",
        }


def _build_single_file_review_prompt(
    file: Dict[str, Any], pr_info: Dict[str, Any]
) -> str:
    """æ„å»ºå•æ–‡ä»¶å®¡æŸ¥æç¤º"""
    filename = file.get("filename", "unknown")
    status = file.get("status", "modified")
    additions = file.get("additions", 0)
    deletions = file.get("deletions", 0)
    patch = _safe_get_string(file.get("patch", ""))
    content = _safe_get_string(file.get("content", ""))

    prompt = f"""
ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„ä»£ç å®¡æŸ¥ä¸“å®¶ã€‚è¯·å¯¹ä»¥ä¸‹å•ä¸ªæ–‡ä»¶è¿›è¡Œè¯¦ç»†çš„ä»£ç å®¡æŸ¥ã€‚

## PRèƒŒæ™¯ä¿¡æ¯
- æ ‡é¢˜: {_safe_get_string(pr_info.get('title', ''))}
- ä½œè€…: {_safe_get_user_login(pr_info)}

## æ–‡ä»¶ä¿¡æ¯
- æ–‡ä»¶å: {filename}
- çŠ¶æ€: {status}
- æ–°å¢è¡Œæ•°: {additions}
- åˆ é™¤è¡Œæ•°: {deletions}

## å˜æ›´å†…å®¹ (diff):
```diff
{patch[:1500]}{'...' if len(patch) > 1500 else ''}
```

## å®Œæ•´æ–‡ä»¶å†…å®¹:
```
{content[:3000]}{'...' if len(content) > 3000 else ''}
```

## å®¡æŸ¥è¦æ±‚
è¯·ä»ä»¥ä¸‹ç»´åº¦å¯¹è¿™ä¸ªæ–‡ä»¶è¿›è¡Œæ·±åº¦å®¡æŸ¥ï¼š

1. **ä»£ç è´¨é‡** (0-100åˆ†):
   - å¯è¯»æ€§å’Œå¯ç»´æŠ¤æ€§
   - ä»£ç å¤æ‚åº¦
   - å‘½åè§„èŒƒ
   - ä»£ç ç»“æ„

2. **å®‰å…¨æ€§** (0-100åˆ†):
   - æ½œåœ¨å®‰å…¨æ¼æ´
   - è¾“å…¥éªŒè¯
   - æƒé™æ§åˆ¶
   - æ•°æ®å¤„ç†å®‰å…¨

3. **ä¸šåŠ¡é€»è¾‘** (0-100åˆ†):
   - é€»è¾‘æ­£ç¡®æ€§
   - è¾¹ç•Œæ¡ä»¶å¤„ç†
   - é”™è¯¯å¤„ç†
   - ä¸šåŠ¡è§„åˆ™ç¬¦åˆæ€§

4. **æ€§èƒ½** (0-100åˆ†):
   - ç®—æ³•æ•ˆç‡
   - èµ„æºä½¿ç”¨
   - æ½œåœ¨æ€§èƒ½ç“¶é¢ˆ

5. **æœ€ä½³å®è·µ** (0-100åˆ†):
   - ç¼–ç è§„èŒƒ
   - è®¾è®¡æ¨¡å¼
   - æ–‡æ¡£æ³¨é‡Š
   - æµ‹è¯•è¦†ç›–

## è¾“å‡ºæ ¼å¼
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›å®¡æŸ¥ç»“æœï¼Œç¡®ä¿JSONæ ¼å¼æ­£ç¡®ï¼š

```json
{{
    "filename": "{filename}",
    "overall_score": 85,
    "code_quality_score": 80,
    "security_score": 90,
    "business_score": 85,
    "performance_score": 80,
    "best_practices_score": 85,
    "issues": [
        {{
            "type": "warning",
            "title": "é—®é¢˜æ ‡é¢˜",
            "description": "è¯¦ç»†æè¿°",
            "line": 45,
            "severity": "warning",
            "category": "code_quality",
            "suggestion": "æ”¹è¿›å»ºè®®"
        }}
    ],
    "positive_points": [
        "ä¼˜ç‚¹1",
        "ä¼˜ç‚¹2"
    ],
    "summary": "å¯¹è¯¥æ–‡ä»¶çš„æ€»ä½“è¯„ä»·å’Œå»ºè®®"
}}
```

**é‡è¦æç¤º**ï¼š
1. å¿…é¡»è¿”å›æœ‰æ•ˆçš„JSONæ ¼å¼
2. æ‰€æœ‰å­—ç¬¦ä¸²å€¼å¿…é¡»ç”¨åŒå¼•å·åŒ…å›´
3. æ•°å­—å€¼ä¸è¦ç”¨å¼•å·
4. issues ä¸­æ¯ä¸ªé—®é¢˜å¿…é¡»åŒ…å« severity å’Œ category å­—æ®µ
5. severity å¯é€‰å€¼: "info", "warning", "error", "critical"
6. category å¯é€‰å€¼: "code_quality", "security", "performance", "best_practices", "documentation", "other"
"""
    return prompt


def _parse_single_file_response(response: str, file: Dict[str, Any]) -> Dict[str, Any]:
    """è§£æå•æ–‡ä»¶å®¡æŸ¥å“åº”"""
    import json
    import re

    filename = file.get("filename", "unknown")

    try:
        # å°è¯•æå–JSON - æ”¹è¿›çš„æ­£åˆ™è¡¨è¾¾å¼
        json_patterns = [
            r"```json\s*(.*?)\s*```",  # æ ‡å‡† json ä»£ç å—
            r"```\s*(.*?)\s*```",  # æ™®é€šä»£ç å—
            r"\{.*\}",  # ç›´æ¥çš„ JSON å¯¹è±¡
        ]

        json_str = None
        for pattern in json_patterns:
            json_match = re.search(pattern, response, re.DOTALL)
            if json_match:
                json_str = (
                    json_match.group(1) if pattern != r"\{.*\}" else json_match.group(0)
                )
                break

        if not json_str:
            # æŸ¥æ‰¾ç¬¬ä¸€ä¸ª{åˆ°æœ€åä¸€ä¸ª}
            start = response.find("{")
            end = response.rfind("}") + 1
            if start != -1 and end > start:
                json_str = response[start:end]
            else:
                raise ValueError("æœªæ‰¾åˆ°JSONæ ¼å¼")

        # æ¸…ç† JSON å­—ç¬¦ä¸²
        json_str = json_str.strip()

        # è§£æJSON
        result = json.loads(json_str)

        # ç¡®ä¿å¿…è¦å­—æ®µå­˜åœ¨
        issues = result.get("issues", [])
        # éªŒè¯å’Œä¿®å¤ issues æ ¼å¼
        validated_issues = []
        for issue in issues:
            if isinstance(issue, dict):
                # ç¡®ä¿å¿…éœ€å­—æ®µå­˜åœ¨
                validated_issue = {
                    "type": issue.get("type", "info"),
                    "title": issue.get("title", "æœªçŸ¥é—®é¢˜"),
                    "description": issue.get("description", ""),
                    "line": issue.get("line", issue.get("line_start")),
                    "suggestion": issue.get("suggestion", ""),
                    "severity": issue.get(
                        "severity", issue.get("type", "info")
                    ),  # ç¡®ä¿æœ‰ severity
                    "category": issue.get("category", "other"),  # ç¡®ä¿æœ‰ category
                }
                validated_issues.append(validated_issue)

        file_review = {
            "filename": filename,
            "score": _safe_get_score(result.get("overall_score", 80)),
            "code_quality_score": _safe_get_score(result.get("code_quality_score", 80)),
            "security_score": _safe_get_score(result.get("security_score", 80)),
            "business_score": _safe_get_score(result.get("business_score", 80)),
            "performance_score": _safe_get_score(result.get("performance_score", 80)),
            "best_practices_score": _safe_get_score(
                result.get("best_practices_score", 80)
            ),
            "issues": validated_issues,
            "positive_points": result.get("positive_points", []),
            "summary": result.get("summary", f"æ–‡ä»¶ {filename} å®¡æŸ¥å®Œæˆ"),
        }

        return file_review

    except Exception as e:
        logger.error(f"è§£æå•æ–‡ä»¶å“åº”å¤±è´¥ {filename}: {e}")
        logger.debug(f"åŸå§‹å“åº”å†…å®¹: {response[:500]}...")  # è®°å½•å‰500å­—ç¬¦ç”¨äºè°ƒè¯•
        # è¿”å›é»˜è®¤ç»“æœ
        return {
            "filename": filename,
            "score": 75,
            "code_quality_score": 75,
            "security_score": 75,
            "business_score": 75,
            "performance_score": 75,
            "best_practices_score": 75,
            "issues": [
                {
                    "type": "warning",
                    "title": "è§£æå¤±è´¥",
                    "description": f"LLM å“åº”è§£æå¤±è´¥: {str(e)}",
                    "severity": "warning",
                    "category": "other",
                    "suggestion": "è¯·æ£€æŸ¥ LLM è¾“å‡ºæ ¼å¼",
                }
            ],
            "positive_points": ["æ–‡ä»¶å·²å®¡æŸ¥"],
            "summary": f"æ–‡ä»¶ {filename} å®¡æŸ¥å®Œæˆï¼ˆè§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤ç»“æœï¼‰",
        }


def _safe_get_score(score: Any) -> int:
    """å®‰å…¨åœ°è·å–è¯„åˆ†"""
    try:
        if isinstance(score, (int, float)):
            return max(0, min(100, int(score)))
        elif isinstance(score, str):
            return max(0, min(100, int(float(score))))
        else:
            return 80
    except (ValueError, TypeError):
        return 80


def _calculate_overall_scores(file_reviews: List[Dict[str, Any]]) -> Dict[str, Any]:
    """è®¡ç®—æ€»ä½“è¯„åˆ†"""
    if not file_reviews:
        return {
            "overall_score": 100,
            "code_quality_score": 100,
            "security_score": 100,
            "business_score": 100,
            "summary": "æ²¡æœ‰æ–‡ä»¶éœ€è¦å®¡æŸ¥",
            "standards_passed": 0,
            "standards_failed": 0,
            "standards_total": 0,
        }

    # è®¡ç®—å„ç»´åº¦å¹³å‡åˆ†ï¼ˆä½¿ç”¨å®‰å…¨çš„è¯„åˆ†è·å–ï¼‰
    total_files = len(file_reviews)

    avg_code_quality = (
        sum(_safe_get_score(fr.get("code_quality_score", 80)) for fr in file_reviews)
        / total_files
    )
    avg_security = (
        sum(_safe_get_score(fr.get("security_score", 80)) for fr in file_reviews)
        / total_files
    )
    avg_business = (
        sum(_safe_get_score(fr.get("business_score", 80)) for fr in file_reviews)
        / total_files
    )
    avg_performance = (
        sum(_safe_get_score(fr.get("performance_score", 80)) for fr in file_reviews)
        / total_files
    )
    avg_best_practices = (
        sum(_safe_get_score(fr.get("best_practices_score", 80)) for fr in file_reviews)
        / total_files
    )

    # è®¡ç®—æ€»ä½“è¯„åˆ†ï¼ˆåŠ æƒå¹³å‡ï¼‰
    overall_score = (
        avg_code_quality * 0.25
        + avg_security * 0.25
        + avg_business * 0.25
        + avg_performance * 0.125
        + avg_best_practices * 0.125
    )

    # ç»Ÿè®¡é—®é¢˜æ•°é‡ï¼ˆä½¿ç”¨å®‰å…¨çš„è¯„åˆ†è·å–ï¼‰
    total_issues = sum(len(fr.get("issues", [])) for fr in file_reviews)
    high_score_files = sum(
        1 for fr in file_reviews if _safe_get_score(fr.get("score", 80)) >= 85
    )

    # ç”Ÿæˆæ€»ç»“
    summary = f"å®¡æŸ¥äº† {total_files} ä¸ªæ–‡ä»¶ï¼Œå‘ç° {total_issues} ä¸ªé—®é¢˜ï¼Œ{high_score_files} ä¸ªæ–‡ä»¶è´¨é‡ä¼˜ç§€"

    return {
        "overall_score": round(overall_score, 1),
        "code_quality_score": round(avg_code_quality, 1),
        "security_score": round(avg_security, 1),
        "business_score": round(avg_business, 1),
        "performance_score": round(avg_performance, 1),
        "best_practices_score": round(avg_best_practices, 1),
        "summary": summary,
        "standards_passed": max(0, total_files * 5 - total_issues),  # ä¼°ç®—
        "standards_failed": total_issues,
        "standards_total": total_files * 5,
    }


def _safe_get_user_login(pr_info: Dict[str, Any]) -> str:
    """å®‰å…¨åœ°è·å–ç”¨æˆ·ç™»å½•å"""
    try:
        user = pr_info.get("user", "")
        if isinstance(user, dict):
            return user.get("login", "unknown")
        elif isinstance(user, str):
            return user
        else:
            return "unknown"
    except Exception as e:
        logger.warning(f"è·å–ç”¨æˆ·ç™»å½•åå¤±è´¥: {e}")
        return "unknown"


def _safe_get_string(data: Any, default: str = "") -> str:
    """å®‰å…¨åœ°è·å–å­—ç¬¦ä¸²å€¼"""
    if data is None:
        return default
    return str(data)


def _build_comprehensive_review_prompt(
    pr_info: Dict[str, Any], files: List[Dict[str, Any]]
) -> str:
    """æ„å»ºç»¼åˆå®¡æŸ¥æç¤º"""

    # æ„å»ºæ–‡ä»¶ä¿¡æ¯
    files_info = []
    for file in files:
        file_info = f"""
## æ–‡ä»¶: {file.get('filename', 'unknown')}
- çŠ¶æ€: {file.get('status', 'unknown')}
- æ–°å¢è¡Œæ•°: {file.get('additions', 0)}
- åˆ é™¤è¡Œæ•°: {file.get('deletions', 0)}

### å˜æ›´å†…å®¹ (diff):
```diff
{_safe_get_string(file.get('patch', 'æ— diffä¿¡æ¯'))[:1000]}...
```

### å®Œæ•´æ–‡ä»¶å†…å®¹:
```
{_safe_get_string(file.get('content', 'æ— æ³•è·å–æ–‡ä»¶å†…å®¹'))[:2000]}...
```
"""
        files_info.append(file_info)

    files_text = "\n".join(files_info)

    prompt = f"""
ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„ä»£ç å®¡æŸ¥ä¸“å®¶ã€‚è¯·å¯¹ä»¥ä¸‹PRè¿›è¡Œå…¨é¢çš„ä»£ç å®¡æŸ¥ã€‚

## PRä¿¡æ¯
- æ ‡é¢˜: {_safe_get_string(pr_info.get('title', ''))}
- æè¿°: {_safe_get_string(pr_info.get('body', ''))[:500]}...
- ä½œè€…: {_safe_get_user_login(pr_info)}

## ä»£ç æ–‡ä»¶åˆ†æ
{files_text}

## å®¡æŸ¥è¦æ±‚
è¯·ä»ä»¥ä¸‹ç»´åº¦å¯¹æ¯ä¸ªæ–‡ä»¶è¿›è¡Œå®¡æŸ¥ï¼š
1. **ä»£ç è´¨é‡**: å¯è¯»æ€§ã€å¯ç»´æŠ¤æ€§ã€å¤æ‚åº¦
2. **å®‰å…¨æ€§**: æ½œåœ¨å®‰å…¨æ¼æ´ã€è¾“å…¥éªŒè¯
3. **ä¸šåŠ¡é€»è¾‘**: é€»è¾‘æ­£ç¡®æ€§ã€è¾¹ç•Œæ¡ä»¶å¤„ç†
4. **æ€§èƒ½**: ç®—æ³•æ•ˆç‡ã€èµ„æºä½¿ç”¨
5. **æœ€ä½³å®è·µ**: ç¼–ç è§„èŒƒã€è®¾è®¡æ¨¡å¼

## è¾“å‡ºæ ¼å¼
è¯·ä»¥JSONæ ¼å¼è¿”å›å®¡æŸ¥ç»“æœï¼š
```json
{{
    "overall_score": 85,
    "code_quality_score": 80,
    "security_score": 90,
    "business_score": 85,
    "file_reviews": [
        {{
            "filename": "src/main.py",
            "score": 85,
            "issues": [
                {{
                    "type": "warning",
                    "title": "å‡½æ•°å¤æ‚åº¦è¿‡é«˜",
                    "description": "process_dataå‡½æ•°åŒ…å«è¿‡å¤šé€»è¾‘åˆ†æ”¯",
                    "line": 45,
                    "suggestion": "å»ºè®®æ‹†åˆ†ä¸ºå¤šä¸ªå°å‡½æ•°"
                }}
            ],
            "positive_points": ["è‰¯å¥½çš„é”™è¯¯å¤„ç†", "æ¸…æ™°çš„å˜é‡å‘½å"]
        }}
    ],
    "summary": "æ•´ä½“ä»£ç è´¨é‡è‰¯å¥½ï¼Œå»ºè®®ä¼˜åŒ–å‡½æ•°å¤æ‚åº¦"
}}
```

è¯·ç¡®ä¿è¿”å›æœ‰æ•ˆçš„JSONæ ¼å¼ã€‚
"""
    return prompt


# æ—§çš„è§£æå‡½æ•°å·²ç§»åŠ¨åˆ° output_parser.py ä¸­


def _fallback_simple_review(state: AgentState) -> AgentState:
    """é™çº§åˆ°ç®€å•å®¡æŸ¥"""
    files = state["files"]

    file_reviews = []
    for file in files:
        file_reviews.append(
            {
                "filename": file["filename"],
                "score": 80,
                "issues": [],
                "positive_points": ["ç®€å•å®¡æŸ¥å®Œæˆ"],
            }
        )

    return {
        **state,
        "file_reviews": file_reviews,
        "overall_summary": "ä½¿ç”¨ç®€å•å®¡æŸ¥æ¨¡å¼å®Œæˆ",
        "enhanced_analysis": {
            "overall_score": 80,
            "code_quality_score": 80,
            "security_score": 80,
            "business_score": 80,
            "file_results": file_reviews,
            "summary": "ä½¿ç”¨ç®€å•å®¡æŸ¥æ¨¡å¼å®Œæˆ",
            "standards_passed": len(files) * 3,  # ä¼°ç®—
            "standards_failed": len(files) * 2,  # ä¼°ç®—
            "standards_total": len(files) * 5,
        },
    }


async def run_code_review_async(pr_info: Dict[str, Any]) -> Dict[str, Any]:
    """å¼‚æ­¥è¿è¡Œä»£ç å®¡æŸ¥

    Args:
        pr_info: PR ä¿¡æ¯ï¼ŒåŒ…å« repo å’Œ number

    Returns:
        å®¡æŸ¥ç»“æœ
    """
    # æ„é€ å·¥ä½œæµ
    graph = build_code_review_graph()

    # åˆå§‹çŠ¶æ€
    initial_state = {
        "messages": [],
        "pr_info": pr_info,
        "files": [],
        "file_contents": {},
        "current_file_index": 0,
        "file_reviews": [],
        "overall_summary": None,
        "enhanced_analysis": None,
        "db_record_id": None,
    }

    # å¼‚æ­¥æ‰§è¡Œå›¾
    result = await graph.ainvoke(initial_state)
    return result


def run_code_review(pr_info: Dict[str, Any]) -> Dict[str, Any]:
    """è¿è¡Œä»£ç å®¡æŸ¥ - åŒæ­¥åŒ…è£…å™¨

    Args:
        pr_info: PR ä¿¡æ¯ï¼ŒåŒ…å« repo å’Œ number

    Returns:
        å®¡æŸ¥ç»“æœ
    """
    import asyncio

    # è·å–æˆ–åˆ›å»ºäº‹ä»¶å¾ªç¯
    try:
        loop = asyncio.get_event_loop()
        if loop.is_running():
            # å¦‚æœäº‹ä»¶å¾ªç¯æ­£åœ¨è¿è¡Œï¼Œåˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯
            import concurrent.futures

            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(asyncio.run, run_code_review_async(pr_info))
                return future.result()
        else:
            # å¦‚æœäº‹ä»¶å¾ªç¯æ²¡æœ‰è¿è¡Œï¼Œç›´æ¥ä½¿ç”¨
            return loop.run_until_complete(run_code_review_async(pr_info))
    except RuntimeError:
        # å¦‚æœæ²¡æœ‰äº‹ä»¶å¾ªç¯ï¼Œåˆ›å»ºæ–°çš„
        return asyncio.run(run_code_review_async(pr_info))
