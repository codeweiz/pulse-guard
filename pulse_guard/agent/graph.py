import asyncio
import logging
from typing import Any, Dict, List, Optional, Union
from langgraph.graph import END, StateGraph
from pulse_guard.llm.client import get_llm
from pulse_guard.models.review import (
    CodeIssue,
    FileReview,
    IssueCategory,
    PRReview,
    SeverityLevel,
)
from pulse_guard.models.workflow import (
    AgentState,
    CodeIssueInfo,
    EnhancedAnalysis,
    FileInfo,
    FileReviewInfo,
    PRInfo,
    UserInfo,
)
from pulse_guard.platforms import get_platform_provider
from pulse_guard.utils.file_type_utils import is_code_file

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)


def fetch_pr_and_code_files(state: AgentState) -> AgentState:
    """è·å–PRä¿¡æ¯å’Œä»£ç æ–‡ä»¶å†…å®¹"""
    pr_info = state.pr_info
    platform = pr_info.platform

    # è·å–å¹³å°æä¾›è€…
    provider = get_platform_provider(platform)

    # è·å– PR è¯¦ç»†ä¿¡æ¯
    pr_details = provider.get_pr_info(pr_info.repo, pr_info.number)

    # ä» pr_details ä¸­ç§»é™¤å¯èƒ½å†²çªçš„å­—æ®µ
    safe_pr_details = {k: v for k, v in pr_details.items()
                       if k not in ['repo', 'number', 'platform', 'author']}

    updated_pr_info = PRInfo(
        repo=pr_info.repo,
        number=pr_info.number,
        platform=pr_info.platform,
        author=pr_info.author,
        **safe_pr_details
    )

    # è·å– PR ä¿®æ”¹çš„æ–‡ä»¶åˆ—è¡¨
    all_files = provider.get_pr_files(pr_info.repo, pr_info.number)

    # è½¬æ¢ä¸º FileInfo æ¨¡å‹
    file_infos = []
    for file_data in all_files:
        try:
            file_info = FileInfo(**file_data)
            file_infos.append(file_info)
        except Exception as e:
            logger.warning(f"è·³è¿‡æ— æ•ˆæ–‡ä»¶æ•°æ®: {e}")
            continue

    # è¿‡æ»¤å‡ºä»£ç æ–‡ä»¶
    code_files = [f for f in file_infos if is_code_file(f.filename)]

    logger.info(
        f"æ€»æ–‡ä»¶æ•°: {len(all_files)}, æœ‰æ•ˆæ–‡ä»¶æ•°: {len(file_infos)}, ä»£ç æ–‡ä»¶æ•°: {len(code_files)}"
    )

    # è·å–æ‰€æœ‰ä»£ç æ–‡ä»¶çš„å†…å®¹
    file_contents = {}
    enhanced_files = []

    for file in code_files:
        if file.status != "removed":
            try:
                content = provider.get_file_content(
                    updated_pr_info.repo_full_name,
                    file.filename,
                    updated_pr_info.head_sha,
                )
                file_contents[file.filename] = content
                # æ›´æ–°æ–‡ä»¶å†…å®¹
                file.content = content
            except Exception as e:
                # å¦‚æœè·å–æ–‡ä»¶å†…å®¹å¤±è´¥ï¼Œè®°å½•é”™è¯¯
                error_msg = f"Error fetching file content: {str(e)}"
                file_contents[file.filename] = error_msg
                file.content = error_msg
                logger.warning(f"è·å–æ–‡ä»¶å†…å®¹å¤±è´¥ {file.filename}: {e}")

        enhanced_files.append(file)

    # æ›´æ–°çŠ¶æ€
    new_state = state.model_copy()
    new_state.pr_info = updated_pr_info
    new_state.files = enhanced_files
    new_state.file_contents = file_contents
    new_state.current_file_index = 0
    new_state.file_reviews = []

    return new_state


async def intelligent_code_review(state: AgentState) -> AgentState:
    """æ™ºèƒ½ä»£ç å®¡æŸ¥"""
    pr_info = state.pr_info
    files = state.files

    if not files:
        logger.warning("æ²¡æœ‰ä»£ç æ–‡ä»¶éœ€è¦å®¡æŸ¥")
        new_state = state.model_copy()
        new_state.file_reviews = []
        new_state.overall_summary = "æ²¡æœ‰ä»£ç æ–‡ä»¶éœ€è¦å®¡æŸ¥"
        new_state.enhanced_analysis = EnhancedAnalysis(
            overall_score=100,
            code_quality_score=100,
            security_score=100,
            business_score=100,
            file_results=[],
            summary="æ²¡æœ‰ä»£ç æ–‡ä»¶éœ€è¦å®¡æŸ¥",
        )
        return new_state

    logger.info(f"å¼€å§‹å¹¶å‘å®¡æŸ¥ {len(files)} ä¸ªä»£ç æ–‡ä»¶")

    # å¹¶å‘å®¡æŸ¥æ¯ä¸ªæ–‡ä»¶
    file_reviews = []
    try:
        logger.info(f"ä½¿ç”¨ asyncio.gather å¹¶å‘å¤„ç† {len(files)} ä¸ªæ–‡ä»¶")

        # åˆ›å»ºæ‰€æœ‰æ–‡ä»¶å®¡æŸ¥ä»»åŠ¡
        tasks = []
        for file in files:
            task = _review_single_file_async(file, pr_info)
            tasks.append(task)

        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        results = await asyncio.gather(*tasks, return_exceptions=True)

        # å¤„ç†ç»“æœ
        for i, (file, result) in enumerate(zip(files, results)):
            if isinstance(result, Exception):
                logger.error(f"æ–‡ä»¶ {file.filename} å®¡æŸ¥å¼‚å¸¸: {result}")
                # æ·»åŠ å¤±è´¥çš„é»˜è®¤ç»“æœ
                file_review = FileReviewInfo(
                    filename=file.filename,
                    score=70,
                    issues=[
                        CodeIssueInfo(
                            type="error",
                            title="å®¡æŸ¥å¤±è´¥",
                            description=str(result),
                        )
                    ],
                    positive_points=[],
                    summary=f"å®¡æŸ¥å¤±è´¥: {str(result)}",
                )
                file_reviews.append(file_review)
            else:
                # å°†å­—å…¸ç»“æœè½¬æ¢ä¸ºFileReviewInfoæ¨¡å‹
                if isinstance(result, dict):
                    issues = []
                    for issue_data in result.get("issues", []):
                        try:
                            issue = CodeIssueInfo(**issue_data)
                            issues.append(issue)
                        except Exception as e:
                            logger.warning(f"è½¬æ¢é—®é¢˜ä¿¡æ¯å¤±è´¥: {e}")
                            continue

                    file_review = FileReviewInfo(
                        filename=result.get("filename", file.filename),
                        score=result.get("score", 80),
                        code_quality_score=result.get("code_quality_score", 80),
                        security_score=result.get("security_score", 80),
                        business_score=result.get("business_score", 80),
                        performance_score=result.get("performance_score", 80),
                        best_practices_score=result.get("best_practices_score", 80),
                        issues=issues,
                        positive_points=result.get("positive_points", []),
                        summary=result.get("summary", ""),
                    )
                    file_reviews.append(file_review)
                else:
                    # å¦‚æœresultä¸æ˜¯å­—å…¸ï¼Œåˆ›å»ºä¸€ä¸ªé»˜è®¤çš„FileReviewInfo
                    logger.warning(f"æ„å¤–çš„ç»“æœç±»å‹: {type(result)}, åˆ›å»ºé»˜è®¤å®¡æŸ¥ç»“æœ")
                    file_review = FileReviewInfo(
                        filename=file.filename,
                        score=70,
                        issues=[
                            CodeIssueInfo(
                                type="warning",
                                title="å®¡æŸ¥ç»“æœè§£æå¼‚å¸¸",
                                description=f"æ— æ³•è§£æå®¡æŸ¥ç»“æœ: {str(result)}",
                            )
                        ],
                        positive_points=[],
                        summary="å®¡æŸ¥ç»“æœè§£æå¼‚å¸¸",
                    )
                    file_reviews.append(file_review)
                logger.info(f"æ–‡ä»¶ {file.filename} å®¡æŸ¥å®Œæˆ")

        # è®¡ç®—æ€»ä½“è¯„åˆ†
        overall_result = _calculate_overall_scores(
            [fr.model_dump() if isinstance(fr, FileReviewInfo) else fr for fr in file_reviews])

        logger.info(f"å¹¶å‘å®¡æŸ¥å®Œæˆï¼Œæ€»ä½“è¯„åˆ†: {overall_result['overall_score']}")

        # åˆ›å»ºå¢å¼ºåˆ†æç»“æœ
        enhanced_analysis = EnhancedAnalysis(
            overall_score=overall_result.get("overall_score", 80),
            code_quality_score=overall_result.get("code_quality_score", 80),
            security_score=overall_result.get("security_score", 80),
            business_score=overall_result.get("business_score", 80),
            file_results=file_reviews,
            summary=overall_result.get("summary", "å¹¶å‘å®¡æŸ¥å®Œæˆ"),
            standards_passed=overall_result.get("standards_passed", 0),
            standards_failed=overall_result.get("standards_failed", 0),
            standards_total=overall_result.get("standards_total", 0),
        )

        # æ›´æ–°çŠ¶æ€
        new_state = state.model_copy()
        new_state.file_reviews = file_reviews
        new_state.overall_summary = overall_result.get("summary", "å¹¶å‘å®¡æŸ¥å®Œæˆ")
        new_state.enhanced_analysis = enhanced_analysis

        return new_state

    except Exception as e:
        logger.error(f"å¹¶å‘å®¡æŸ¥å¤±è´¥: {e}")
        # é™çº§åˆ°ç®€å•å®¡æŸ¥
        return state


def generate_summary(state: AgentState) -> AgentState:
    """ç”Ÿæˆæ€»ä½“è¯„ä»·"""
    file_reviews = state.file_reviews
    enhanced_analysis = state.enhanced_analysis

    # å¦‚æœæœ‰å¢å¼ºåˆ†æç»“æœï¼Œä¼˜å…ˆä½¿ç”¨
    if enhanced_analysis:
        new_state = state.model_copy()
        new_state.overall_summary = enhanced_analysis.summary
        return new_state

    # å¦‚æœæ²¡æœ‰æ–‡ä»¶å®¡æŸ¥ç»“æœï¼Œè¿”å›é»˜è®¤æ€»ç»“
    if not file_reviews:
        new_state = state.model_copy()
        new_state.overall_summary = "æ²¡æœ‰æ‰¾åˆ°éœ€è¦å®¡æŸ¥çš„æ–‡ä»¶ã€‚"
        return new_state

    # æ„å»ºæ–‡ä»¶å®¡æŸ¥æ‘˜è¦
    file_reviews_text = ""
    for review in file_reviews:
        if isinstance(review, FileReviewInfo):
            filename = review.filename
            summary = review.summary
            issues_count = len(review.issues)

            file_reviews_text += f"## {filename}\n"
            file_reviews_text += f"- æ‘˜è¦: {summary}\n"
            file_reviews_text += f"- é—®é¢˜æ•°: {issues_count}\n"

            if issues_count > 0:
                file_reviews_text += "- é—®é¢˜åˆ—è¡¨:\n"
                for issue in review.issues:
                    file_reviews_text += f"  - [{issue.severity}] {issue.title}\n"
        else:
            # å‘åå…¼å®¹å­—å…¸æ ¼å¼
            filename = review.get("filename", "unknown")
            summary = review.get("summary", "")
            issues_count = len(review.get("issues", []))

            file_reviews_text += f"## {filename}\n"
            file_reviews_text += f"- æ‘˜è¦: {summary}\n"
            file_reviews_text += f"- é—®é¢˜æ•°: {issues_count}\n"

            if issues_count > 0:
                file_reviews_text += "- é—®é¢˜åˆ—è¡¨:\n"
                for issue in review.get("issues", []):
                    severity = issue.get("severity", "medium") if isinstance(issue, dict) else getattr(issue,
                                                                                                       "severity",
                                                                                                       "medium")
                    title = issue.get("title", "") if isinstance(issue, dict) else getattr(issue, "title", "")
                    file_reviews_text += f"  - [{severity}] {title}\n"

        file_reviews_text += "\n"

    # ä½¿ç”¨ LLM ç”Ÿæˆæ€»ä½“è¯„ä»·
    llm = get_llm()

    prompt = f"""
è¯·æ ¹æ®ä»¥ä¸‹å„æ–‡ä»¶çš„ä»£ç å®¡æŸ¥ç»“æœï¼Œç”Ÿæˆä¸€ä¸ªæ€»ä½“è¯„ä»·:

{file_reviews_text}

è¯·åœ¨æ€»ç»“ä¸­åŒ…æ‹¬:
1. PR çš„æ•´ä½“è´¨é‡è¯„ä»·ï¼Œä» 0 åˆ° 10 åˆ†ç»™ PR è¯„åˆ†
2. ä¸»è¦é—®é¢˜å’Œæ¨¡å¼
3. å…³é”®æ”¹è¿›å»ºè®®
4. ç§¯æçš„åé¦ˆå’Œé¼“åŠ±

ä½ çš„æ€»ç»“å°†ä½œä¸º PR è¯„è®ºçš„å¼€å¤´éƒ¨åˆ†ï¼Œåº”è¯¥å‹å¥½ã€ä¸“ä¸šä¸”æœ‰å»ºè®¾æ€§ã€‚

è¯·ä½¿ç”¨ä¸­æ–‡å›å¤ã€‚
"""

    # è·å– LLM å“åº”
    response = llm.invoke(prompt)
    overall_summary = str(response.content if hasattr(response, 'content') else response)

    # æ›´æ–°çŠ¶æ€
    new_state = state.model_copy()
    new_state.overall_summary = overall_summary
    return new_state


def post_review_comment(state: AgentState) -> AgentState:
    """å‘å¸ƒå®¡æŸ¥è¯„è®ºå¹¶ä¿å­˜åˆ°æ•°æ®åº“"""
    pr_info = state.pr_info
    platform = pr_info.platform
    file_reviews = state.file_reviews
    overall_summary = state.overall_summary
    enhanced_analysis = state.enhanced_analysis

    # é¦–å…ˆä¿å­˜å®¡æŸ¥ç»“æœåˆ°æ•°æ®åº“
    try:
        from pulse_guard.database import DatabaseManager

        db_record_id = DatabaseManager.save_complete_review_result(
            repo_full_name=pr_info.repo_full_name,
            pr_number=pr_info.number,
            pr_title=pr_info.title,
            pr_description=pr_info.body,
            pr_author=pr_info.author.login,
            platform=platform,
            review_result={
                "enhanced_analysis": enhanced_analysis.model_dump() if enhanced_analysis else None,
                "file_reviews": [fr.model_dump() if isinstance(fr, FileReviewInfo) else fr for fr in file_reviews],
            },
        )
        logger.info(f"å®¡æŸ¥ç»“æœå·²ä¿å­˜åˆ°æ•°æ®åº“ï¼Œè®°å½•ID: {db_record_id}")

        # æ›´æ–°çŠ¶æ€ä¸­çš„æ•°æ®åº“è®°å½•ID
        state.db_record_id = db_record_id

    except Exception as e:
        logger.error(f"ä¿å­˜å®¡æŸ¥ç»“æœåˆ°æ•°æ®åº“å¤±è´¥: {e}")
        # ç»§ç»­æ‰§è¡Œï¼Œä¸å› ä¸ºæ•°æ®åº“ä¿å­˜å¤±è´¥è€Œä¸­æ–­è¯„è®ºå‘å¸ƒ

    # åˆ›å»ºå¢å¼ºçš„è¯„è®ºå†…å®¹
    comment_parts = []

    # æ·»åŠ å¢å¼ºåˆ†æç»“æœ
    if enhanced_analysis:
        # å¤„ç†Pydanticå¯¹è±¡æˆ–å­—å…¸æ ¼å¼
        if isinstance(enhanced_analysis, EnhancedAnalysis):
            overall_score = enhanced_analysis.overall_score
            business_score = enhanced_analysis.business_score
            code_quality_score = enhanced_analysis.code_quality_score
            security_score = enhanced_analysis.security_score
            standards_passed = enhanced_analysis.standards_passed
            standards_total = enhanced_analysis.standards_total
            summary = enhanced_analysis.summary
            file_results = enhanced_analysis.file_results
        else:
            # å‘åå…¼å®¹å­—å…¸æ ¼å¼
            overall_score = enhanced_analysis.get("overall_score", 80)
            business_score = enhanced_analysis.get("business_score", 80)
            code_quality_score = enhanced_analysis.get("code_quality_score", 80)
            security_score = enhanced_analysis.get("security_score", 80)
            standards_passed = enhanced_analysis.get("standards_passed", 0)
            standards_total = enhanced_analysis.get("standards_total", 0)
            summary = enhanced_analysis.get("summary", "")
            file_results = enhanced_analysis.get("file_results", [])

        comment_parts.append("# ğŸ” ä»£ç å®¡æŸ¥æŠ¥å‘Š")
        comment_parts.append("")
        comment_parts.append("## ğŸ“Š è¯„åˆ†æ¦‚è§ˆ")
        comment_parts.append(f"- **æ€»ä½“è¯„åˆ†**: {overall_score:.1f}/100")
        comment_parts.append(f"- **ä¸šåŠ¡é€»è¾‘**: {business_score:.1f}/100")
        comment_parts.append(f"- **ä»£ç è´¨é‡**: {code_quality_score:.1f}/100")
        comment_parts.append(f"- **å®‰å…¨æ€§**: {security_score:.1f}/100")
        comment_parts.append(f"- **è§„èŒƒé€šè¿‡ç‡**: {standards_passed}/{standards_total}")
        comment_parts.append("")
        comment_parts.append("## ğŸ“ æ€»ä½“è¯„ä»·")
        comment_parts.append(summary)
        comment_parts.append("")

        # æ·»åŠ æ–‡ä»¶å½±å“åˆ†æ
        if file_results:
            comment_parts.append("## ğŸ“ æ–‡ä»¶å½±å“åˆ†æ")
            for fa in file_results:
                # å¤„ç†FileReviewInfoå¯¹è±¡æˆ–å­—å…¸æ ¼å¼
                if isinstance(fa, FileReviewInfo):
                    filename = fa.filename
                    code_quality_score = fa.code_quality_score
                    security_score = fa.security_score
                    issues_count = len(fa.issues)
                    summary = fa.summary
                    impact_level = "medium"  # é»˜è®¤å€¼ï¼ŒFileReviewInfoæ²¡æœ‰impact_levelå­—æ®µ
                else:
                    # å‘åå…¼å®¹å­—å…¸æ ¼å¼
                    filename = fa.get("filename", "unknown")
                    code_quality_score = fa.get("code_quality_score", 80)
                    security_score = fa.get("security_score", 80)
                    issues_count = len(fa.get("issues", []))
                    summary = fa.get("summary", fa.get("business_impact", "æ— ç‰¹æ®Šå½±å“"))
                    impact_level = fa.get("impact_level", fa.get("type", "medium"))

                impact_emoji = {
                    "low": "ğŸŸ¢",
                    "medium": "ğŸŸ¡",
                    "high": "ğŸŸ ",
                    "critical": "ğŸ”´",
                }.get(impact_level, "âšª")

                comment_parts.append(f"### {impact_emoji} `{filename}`")
                comment_parts.append(f"- **å½±å“çº§åˆ«**: {impact_level}")
                comment_parts.append(f"- **ä»£ç è´¨é‡**: {code_quality_score:.1f}/100")
                comment_parts.append(f"- **å®‰å…¨è¯„åˆ†**: {security_score:.1f}/100")
                comment_parts.append(f"- **é—®é¢˜æ•°é‡**: {issues_count}")
                comment_parts.append(f"- **ä¸šåŠ¡å½±å“**: {summary}")
                comment_parts.append("")

    # åˆ›å»º PR å®¡æŸ¥ç»“æœ - å®‰å…¨åœ°åˆ›å»º CodeIssue å¯¹è±¡
    def _safe_create_code_issue(issue_dict: Dict[str, Any]) -> CodeIssue:
        """å®‰å…¨åœ°åˆ›å»º CodeIssue å¯¹è±¡"""
        try:
            # ç¡®ä¿å¿…éœ€å­—æ®µå­˜åœ¨
            severity_str = issue_dict.get("severity", issue_dict.get("type", "info"))
            category_str = issue_dict.get("category", "other")

            # è½¬æ¢ä¸ºæšä¸¾å€¼
            try:
                severity = SeverityLevel(severity_str.lower())
            except ValueError:
                severity = SeverityLevel.INFO

            try:
                category = IssueCategory(category_str.lower())
            except ValueError:
                category = IssueCategory.OTHER

            return CodeIssue(
                title=issue_dict.get("title", "æœªçŸ¥é—®é¢˜"),
                description=issue_dict.get("description", ""),
                severity=severity,
                category=category,
                line_start=issue_dict.get("line", issue_dict.get("line_start")),
                line_end=issue_dict.get("line", issue_dict.get("line_end")),
                suggestion=issue_dict.get("suggestion", ""),
            )
        except Exception as e:
            logger.warning(f"åˆ›å»º CodeIssue å¤±è´¥: {e}, ä½¿ç”¨é»˜è®¤å€¼")
            return CodeIssue(
                title=issue_dict.get("title", "è§£æå¤±è´¥çš„é—®é¢˜"),
                description=str(issue_dict),
                severity=SeverityLevel.INFO,
                category=IssueCategory.OTHER,
            )

    pr_review = PRReview(
        pr_number=pr_info.number,
        repo_full_name=pr_info.repo_full_name,
        overall_summary=overall_summary or "ä»£ç å®¡æŸ¥å®Œæˆ",
        file_reviews=[
            FileReview(
                filename=review.filename if isinstance(review, FileReviewInfo) else review.get("filename", ""),
                summary=review.summary if isinstance(review, FileReviewInfo) else review.get("summary", ""),
                issues=[
                    _safe_create_code_issue(issue.model_dump() if isinstance(issue, CodeIssueInfo) else issue)
                    for issue in (review.issues if isinstance(review, FileReviewInfo) else review.get("issues", []))
                ],
            )
            for review in file_reviews
        ],
    )

    # ç”Ÿæˆå®Œæ•´çš„è¯„è®ºå†…å®¹ï¼ˆç°åœ¨å¯ä»¥åˆ†æ‰¹å‘é€ï¼‰
    if comment_parts:
        comment_text = "\n".join(comment_parts)
        # æ·»åŠ å®Œæ•´çš„è¯¦ç»†å®¡æŸ¥ç»“æœ
        comment_text += "\n\n" + pr_review.format_comment()
    else:
        comment_text = pr_review.format_comment()

    # è·å–å¹³å°æä¾›è€…å¹¶å‘å¸ƒè¯„è®º
    provider = get_platform_provider(platform)

    try:
        # ä½¿ç”¨åˆ†æ‰¹è¯„è®ºåŠŸèƒ½ï¼Œæ ¹æ®å¹³å°è®¾ç½®ä¸åŒçš„é•¿åº¦é™åˆ¶
        max_length = 4000  # é»˜è®¤é™åˆ¶
        if platform == "gitee":
            max_length = 3000  # Gitee å¯èƒ½é™åˆ¶æ›´ä¸¥æ ¼
        elif platform == "github":
            max_length = 8000  # GitHub é™åˆ¶ç›¸å¯¹å®½æ¾

        results = provider.post_pr_comments_batch(
            pr_info.repo_full_name,
            pr_info.number,
            comment_text,
            max_length=max_length,
        )

        # ç»Ÿè®¡å‘å¸ƒç»“æœ
        success_count = sum(1 for r in results if "error" not in r)
        total_count = len(results)

        if success_count == total_count:
            print(f"âœ… å·²å‘å¸ƒå®¡æŸ¥è¯„è®ºåˆ° PR #{pr_info.number} (å…± {total_count} æ¡)")
        else:
            print(
                f"âš ï¸ éƒ¨åˆ†è¯„è®ºå‘å¸ƒæˆåŠŸ: {success_count}/{total_count} æ¡åˆ° PR #{pr_info.number}"
            )

    except Exception as e:
        print(f"âŒ å‘å¸ƒè¯„è®ºå¤±è´¥: {str(e)}")
        # å¦‚æœåˆ†æ‰¹å‘å¸ƒå¤±è´¥ï¼Œå°è¯•å‘å¸ƒç®€åŒ–ç‰ˆæœ¬
        try:
            simplified_comment = _create_fallback_comment(
                file_reviews, enhanced_analysis  # type: ignore
            )
            provider.post_pr_comment(
                pr_info.repo_full_name, pr_info.number, simplified_comment
            )
            print(f"âœ… å·²å‘å¸ƒç®€åŒ–è¯„è®ºåˆ° PR #{pr_info.number}")
        except Exception as fallback_error:
            print(f"âŒ ç®€åŒ–è¯„è®ºä¹Ÿå‘å¸ƒå¤±è´¥: {str(fallback_error)}")

    # æ›´æ–°çŠ¶æ€
    return state


def _format_simplified_comment(
        pr_review: PRReview, file_reviews: List[Dict[str, Any]]
) -> str:
    """æ ¼å¼åŒ–ç®€åŒ–çš„è¯„è®ºå†…å®¹ï¼Œå‡å°‘é•¿åº¦"""
    comment_parts = []

    # æ·»åŠ ç®€åŒ–çš„æ€»ä½“è¯„ä»·
    if pr_review.overall_summary:
        comment_parts.append("## ğŸ“‹ å®¡æŸ¥æ€»ç»“")
        # é™åˆ¶æ€»ç»“é•¿åº¦
        summary = pr_review.overall_summary
        if len(summary) > 500:
            summary = summary[:500] + "..."
        comment_parts.append(summary)
        comment_parts.append("")

    # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
    total_issues = sum(len(review.get("issues", [])) for review in file_reviews)
    critical_issues = sum(
        1
        for review in file_reviews
        for issue in review.get("issues", [])
        if issue.get("severity") == "critical"
    )

    comment_parts.append("## ğŸ“Š å®¡æŸ¥ç»Ÿè®¡")
    comment_parts.append(f"- ğŸ“ å®¡æŸ¥æ–‡ä»¶: **{len(file_reviews)}** ä¸ª")
    comment_parts.append(f"- ğŸ” å‘ç°é—®é¢˜: **{total_issues}** ä¸ª")
    if critical_issues > 0:
        comment_parts.append(f"- ğŸš¨ ä¸¥é‡é—®é¢˜: **{critical_issues}** ä¸ª")
    comment_parts.append("")

    # åªæ˜¾ç¤ºæœ‰é—®é¢˜çš„æ–‡ä»¶ï¼Œå¹¶é™åˆ¶æ˜¾ç¤ºæ•°é‡
    files_with_issues = [review for review in file_reviews if review.get("issues")]
    if files_with_issues:
        comment_parts.append("## âš ï¸ éœ€è¦å…³æ³¨çš„æ–‡ä»¶")

        # æœ€å¤šæ˜¾ç¤º5ä¸ªæœ‰é—®é¢˜çš„æ–‡ä»¶
        for review in files_with_issues[:5]:
            filename = review["filename"]
            issues = review.get("issues", [])
            issue_count = len(issues)

            # ç»Ÿè®¡é—®é¢˜ä¸¥é‡ç¨‹åº¦
            critical_count = sum(
                1 for issue in issues if issue.get("severity") == "critical"
            )
            error_count = sum(1 for issue in issues if issue.get("severity") == "error")

            severity_info = []
            if critical_count > 0:
                severity_info.append(f"ğŸš¨{critical_count}")
            if error_count > 0:
                severity_info.append(f"âŒ{error_count}")

            severity_text = f" ({', '.join(severity_info)})" if severity_info else ""

            comment_parts.append(f"### `{filename}`")
            comment_parts.append(f"- é—®é¢˜æ•°é‡: **{issue_count}**{severity_text}")

            # åªæ˜¾ç¤ºæœ€ä¸¥é‡çš„é—®é¢˜
            if issues:
                # æŒ‰ä¸¥é‡ç¨‹åº¦æ’åº
                severity_order = {"critical": 0, "error": 1, "warning": 2, "info": 3}
                sorted_issues = sorted(
                    issues,
                    key=lambda x: severity_order.get(x.get("severity", "info"), 3),
                )

                top_issue = sorted_issues[0]
                comment_parts.append(
                    f"- ä¸»è¦é—®é¢˜: {top_issue.get('title', 'æœªçŸ¥é—®é¢˜')}"
                )

            comment_parts.append("")

        # å¦‚æœæœ‰æ›´å¤šæ–‡ä»¶ï¼Œæ˜¾ç¤ºæç¤º
        if len(files_with_issues) > 5:
            remaining = len(files_with_issues) - 5
            comment_parts.append(
                f"*è¿˜æœ‰ {remaining} ä¸ªæ–‡ä»¶å­˜åœ¨é—®é¢˜ï¼Œè¯¦æƒ…è¯·æŸ¥çœ‹å®Œæ•´æŠ¥å‘Š*"
            )
            comment_parts.append("")

    # æ·»åŠ ç®€åŒ–çš„å»ºè®®
    comment_parts.append("## ğŸ’¡ æ”¹è¿›å»ºè®®")
    if critical_issues > 0:
        comment_parts.append("- ğŸš¨ è¯·ä¼˜å…ˆä¿®å¤ä¸¥é‡é—®é¢˜")
    if total_issues > 10:
        comment_parts.append("- ğŸ“ å»ºè®®åˆ†æ‰¹ä¿®å¤é—®é¢˜ï¼Œé¿å…ä¸€æ¬¡æ€§ä¿®æ”¹è¿‡å¤š")
    comment_parts.append("- ğŸ” è¯¦ç»†åˆ†ææŠ¥å‘Šå¯é€šè¿‡ API æ¥å£è·å–")

    return "\n".join(comment_parts)


def _create_fallback_comment(
        file_reviews: List[Union[FileReviewInfo, Dict[str, Any]]],
        enhanced_analysis: Optional[Union[EnhancedAnalysis, Dict[str, Any]]] = None
) -> str:
    """åˆ›å»ºæç®€çš„å¤‡ç”¨è¯„è®ºï¼Œç¡®ä¿èƒ½å¤Ÿå‘å¸ƒ"""
    parts = []

    # åŸºæœ¬ç»Ÿè®¡
    total_files = len(file_reviews)
    total_issues = 0
    critical_issues = 0

    for review in file_reviews:
        if isinstance(review, FileReviewInfo):
            total_issues += len(review.issues)
            critical_issues += sum(1 for issue in review.issues if issue.severity == "critical")
        else:
            # å‘åå…¼å®¹å­—å…¸æ ¼å¼
            total_issues += len(review.get("issues", []))
            critical_issues += sum(
                1 for issue in review.get("issues", [])
                if issue.get("severity") == "critical"
            )

    parts.append("# ğŸ” ä»£ç å®¡æŸ¥å®Œæˆ")
    parts.append("")
    parts.append(f"ğŸ“Š **ç»Ÿè®¡**: {total_files} ä¸ªæ–‡ä»¶ï¼Œ{total_issues} ä¸ªé—®é¢˜")

    if critical_issues > 0:
        parts.append(f"ğŸš¨ **ä¸¥é‡é—®é¢˜**: {critical_issues} ä¸ªï¼Œè¯·ä¼˜å…ˆå¤„ç†")

    if enhanced_analysis:
        if isinstance(enhanced_analysis, EnhancedAnalysis):
            score = enhanced_analysis.overall_score
        else:
            score = enhanced_analysis.get("overall_score", 80)
        parts.append(f"ğŸ“ˆ **æ€»ä½“è¯„åˆ†**: {score:.1f}/100")

    parts.append("")
    parts.append("ğŸ’¡ è¯¦ç»†æŠ¥å‘Šè¯·æŸ¥çœ‹å®Œæ•´åˆ†ææˆ–è”ç³»ç®¡ç†å‘˜")

    return "\n".join(parts)


# æ„å»º LangGraph
def build_code_review_graph() -> Any:
    """æ„å»ºç®€åŒ–çš„ä»£ç å®¡æŸ¥ LangGraph"""
    # åˆ›å»ºå›¾ - ä½¿ç”¨ AgentState è€Œä¸æ˜¯ LangGraphState ä»¥ä¿æŒç±»å‹ä¸€è‡´æ€§
    workflow = StateGraph(AgentState)

    # æ·»åŠ èŠ‚ç‚¹ - ç®€åŒ–çš„æµç¨‹
    workflow.add_node("fetch_pr_and_code_files", fetch_pr_and_code_files)
    workflow.add_node("intelligent_code_review", intelligent_code_review)
    workflow.add_node("post_review_comment", post_review_comment)

    # æ·»åŠ è¾¹ - ç®€åŒ–çš„æµç¨‹
    workflow.add_edge("fetch_pr_and_code_files", "intelligent_code_review")
    workflow.add_edge("intelligent_code_review", "post_review_comment")
    workflow.add_edge("post_review_comment", END)

    # è®¾ç½®å…¥å£ç‚¹
    workflow.set_entry_point("fetch_pr_and_code_files")

    # ç¼–è¯‘å›¾
    return workflow.compile()


# è¿è¡Œä»£ç å®¡æŸ¥
async def _review_single_file_async(
        file: FileInfo, pr_info: PRInfo
) -> Dict[str, Any]:
    """å¼‚æ­¥å®¡æŸ¥å•ä¸ªæ–‡ä»¶"""
    try:
        llm = get_llm()

        # æ„å»ºå•æ–‡ä»¶å®¡æŸ¥æç¤º
        prompt = _build_single_file_review_prompt(file, pr_info)

        # å¼‚æ­¥è°ƒç”¨LLM
        response = await llm.ainvoke(prompt)
        review_content = str(
            response.content if hasattr(response, "content") else response
        )

        # è§£æå•æ–‡ä»¶å®¡æŸ¥ç»“æœ
        file_review = _parse_single_file_response(review_content, file)

        return file_review

    except Exception as e:
        logger.error(f"å•æ–‡ä»¶å®¡æŸ¥å¤±è´¥ {file.filename}: {e}")
        return {
            "filename": file.filename,
            "score": 70,
            "issues": [{"type": "error", "title": "å®¡æŸ¥å¼‚å¸¸", "description": str(e)}],
            "positive_points": [],
            "summary": f"å®¡æŸ¥å¼‚å¸¸: {str(e)}",
        }


def _build_single_file_review_prompt(
        file: FileInfo, pr_info: PRInfo
) -> str:
    """æ„å»ºå•æ–‡ä»¶å®¡æŸ¥æç¤º"""
    filename = file.filename
    status = file.status
    additions = file.additions
    deletions = file.deletions
    patch = _safe_get_string(file.patch)
    content = _safe_get_string(file.content)

    prompt = f"""
ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„ä»£ç å®¡æŸ¥ä¸“å®¶ã€‚è¯·å¯¹ä»¥ä¸‹å•ä¸ªæ–‡ä»¶è¿›è¡Œè¯¦ç»†çš„ä»£ç å®¡æŸ¥ã€‚

## PRèƒŒæ™¯ä¿¡æ¯
- æ ‡é¢˜: {_safe_get_string(pr_info.title)}
- ä½œè€…: {_safe_get_user_login(pr_info)}

## æ–‡ä»¶ä¿¡æ¯
- æ–‡ä»¶å: {filename}
- çŠ¶æ€: {status}
- æ–°å¢è¡Œæ•°: {additions}
- åˆ é™¤è¡Œæ•°: {deletions}

## å˜æ›´å†…å®¹ (diff):
```diff
{patch[:1500]}{'...' if len(patch) > 1500 else ''}
```

## å®Œæ•´æ–‡ä»¶å†…å®¹:
```
{content[:3000]}{'...' if len(content) > 3000 else ''}
```

## å®¡æŸ¥è¦æ±‚
è¯·ä»ä»¥ä¸‹ç»´åº¦å¯¹è¿™ä¸ªæ–‡ä»¶è¿›è¡Œæ·±åº¦å®¡æŸ¥ï¼š

1. **ä»£ç è´¨é‡** (0-100åˆ†):
   - å¯è¯»æ€§å’Œå¯ç»´æŠ¤æ€§
   - ä»£ç å¤æ‚åº¦
   - å‘½åè§„èŒƒ
   - ä»£ç ç»“æ„

2. **å®‰å…¨æ€§** (0-100åˆ†):
   - æ½œåœ¨å®‰å…¨æ¼æ´
   - è¾“å…¥éªŒè¯
   - æƒé™æ§åˆ¶
   - æ•°æ®å¤„ç†å®‰å…¨

3. **ä¸šåŠ¡é€»è¾‘** (0-100åˆ†):
   - é€»è¾‘æ­£ç¡®æ€§
   - è¾¹ç•Œæ¡ä»¶å¤„ç†
   - é”™è¯¯å¤„ç†
   - ä¸šåŠ¡è§„åˆ™ç¬¦åˆæ€§

4. **æ€§èƒ½** (0-100åˆ†):
   - ç®—æ³•æ•ˆç‡
   - èµ„æºä½¿ç”¨
   - æ½œåœ¨æ€§èƒ½ç“¶é¢ˆ

5. **æœ€ä½³å®è·µ** (0-100åˆ†):
   - ç¼–ç è§„èŒƒ
   - è®¾è®¡æ¨¡å¼
   - æ–‡æ¡£æ³¨é‡Š
   - æµ‹è¯•è¦†ç›–

## è¾“å‡ºæ ¼å¼
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›å®¡æŸ¥ç»“æœï¼Œç¡®ä¿JSONæ ¼å¼æ­£ç¡®ï¼š

{{
    "filename": "{filename}",
    "overall_score": 85,
    "code_quality_score": 80,
    "security_score": 90,
    "business_score": 85,
    "performance_score": 80,
    "best_practices_score": 85,
    "issues": [
        {{
            "type": "warning",
            "title": "é—®é¢˜æ ‡é¢˜",
            "description": "è¯¦ç»†æè¿°",
            "line": 45,
            "severity": "warning",
            "category": "code_quality",
            "suggestion": "æ”¹è¿›å»ºè®®"
        }}
    ],
    "positive_points": [
        "ä¼˜ç‚¹1",
        "ä¼˜ç‚¹2"
    ],
    "summary": "å¯¹è¯¥æ–‡ä»¶çš„æ€»ä½“è¯„ä»·å’Œå»ºè®®"
}}


**é‡è¦æç¤º**ï¼š
1. å¿…é¡»è¿”å›æœ‰æ•ˆçš„JSONæ ¼å¼
2. æ‰€æœ‰å­—ç¬¦ä¸²å€¼å¿…é¡»ç”¨åŒå¼•å·åŒ…å›´
3. æ•°å­—å€¼ä¸è¦ç”¨å¼•å·
4. issues ä¸­æ¯ä¸ªé—®é¢˜å¿…é¡»åŒ…å« severity å’Œ category å­—æ®µ
5. severity å¯é€‰å€¼: "info", "warning", "error", "critical"
6. category å¯é€‰å€¼: "code_quality", "security", "performance", "best_practices", "documentation", "other"
"""
    return prompt


def _parse_single_file_response(response: str, file: Union[FileInfo, Dict[str, Any]]) -> Dict[str, Any]:
    """è§£æå•æ–‡ä»¶å®¡æŸ¥å“åº”"""
    import json
    import re

    # å¤„ç†FileInfoå¯¹è±¡æˆ–å­—å…¸æ ¼å¼
    if isinstance(file, FileInfo):
        filename = file.filename
    else:
        filename = file.get("filename", "unknown")

    try:
        # å°è¯•æå–JSON - æ”¹è¿›çš„æ­£åˆ™è¡¨è¾¾å¼
        json_patterns = [
            r"```json\s*(.*?)\s*```",  # æ ‡å‡† json ä»£ç å—
            r"```\s*(.*?)\s*```",  # æ™®é€šä»£ç å—
            r"\{.*\}",  # ç›´æ¥çš„ JSON å¯¹è±¡
        ]

        json_str = None
        for pattern in json_patterns:
            json_match = re.search(pattern, response, re.DOTALL)
            if json_match:
                json_str = (
                    json_match.group(1) if pattern != r"\{.*\}" else json_match.group(0)
                )
                break

        if not json_str:
            # æŸ¥æ‰¾ç¬¬ä¸€ä¸ª{åˆ°æœ€åä¸€ä¸ª}
            start = response.find("{")
            end = response.rfind("}") + 1
            if start != -1 and end > start:
                json_str = response[start:end]
            else:
                # æ²¡æœ‰æ‰¾åˆ° JSON æ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–
                logger.warning(f"æœªæ‰¾åˆ°JSONæ ¼å¼ï¼Œå°è¯•ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–ä¿¡æ¯: {filename}")
                result = _extract_info_with_regex(response, filename)
                # è·³è¿‡ JSON è§£æï¼Œç›´æ¥è¿›å…¥éªŒè¯é˜¶æ®µ
                json_str = None

        # å¦‚æœæ‰¾åˆ°äº† JSON å­—ç¬¦ä¸²ï¼Œå°è¯•è§£æ
        if json_str is not None:
            # æ¸…ç† JSON å­—ç¬¦ä¸²
            json_str = json_str.strip()

            # å°è¯•ä¿®å¤å¸¸è§çš„ JSON æ ¼å¼é—®é¢˜
            json_str = _fix_json_format(json_str)

            # è§£æJSON
            try:
                result = json.loads(json_str)
            except json.JSONDecodeError:
                # å¦‚æœ JSON è§£æå¤±è´¥ï¼Œå°è¯•ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–å…³é”®ä¿¡æ¯
                logger.warning(f"JSONè§£æå¤±è´¥ï¼Œå°è¯•ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–ä¿¡æ¯: {filename}")
                result = _extract_info_with_regex(response, filename)

        # ç¡®ä¿å¿…è¦å­—æ®µå­˜åœ¨
        issues = result.get("issues", [])
        # éªŒè¯å’Œä¿®å¤ issues æ ¼å¼
        validated_issues = []
        for issue in issues:
            if isinstance(issue, dict):
                # ç¡®ä¿å¿…éœ€å­—æ®µå­˜åœ¨
                validated_issue = {
                    "type": issue.get("type", "info"),
                    "title": issue.get("title", "æœªçŸ¥é—®é¢˜"),
                    "description": issue.get("description", ""),
                    "line": issue.get("line", issue.get("line_start")),
                    "suggestion": issue.get("suggestion", ""),
                    "severity": issue.get(
                        "severity", issue.get("type", "info")
                    ),  # ç¡®ä¿æœ‰ severity
                    "category": issue.get("category", "other"),  # ç¡®ä¿æœ‰ category
                }
                validated_issues.append(validated_issue)

        file_review = {
            "filename": filename,
            "score": _safe_get_score(result.get("overall_score", result.get("score", 80))),
            "code_quality_score": _safe_get_score(result.get("code_quality_score", 80)),
            "security_score": _safe_get_score(result.get("security_score", 80)),
            "business_score": _safe_get_score(result.get("business_score", 80)),
            "performance_score": _safe_get_score(result.get("performance_score", 80)),
            "best_practices_score": _safe_get_score(
                result.get("best_practices_score", 80)
            ),
            "issues": validated_issues,
            "positive_points": result.get("positive_points", []),
            "summary": result.get("summary", f"æ–‡ä»¶ {filename} å®¡æŸ¥å®Œæˆ"),
        }

        return file_review

    except json.JSONDecodeError as e:
        logger.error(f"JSONè§£æå¤±è´¥ {filename}: {e}")
        logger.error(f"é”™è¯¯ä½ç½®: è¡Œ{e.lineno}, åˆ—{e.colno}, å­—ç¬¦{e.pos}")
        logger.debug(f"åŸå§‹å“åº”å†…å®¹: {response[:1000]}...")  # è®°å½•å‰1000å­—ç¬¦ç”¨äºè°ƒè¯•
        if 'json_str' in locals():
            logger.debug(f"æ¸…ç†åçš„JSON: {json_str[:1000]}...")
    except Exception as e:
        logger.error(f"è§£æå•æ–‡ä»¶å“åº”å¤±è´¥ {filename}: {e}")
        logger.debug(f"åŸå§‹å“åº”å†…å®¹: {response[:1000]}...")  # è®°å½•å‰1000å­—ç¬¦ç”¨äºè°ƒè¯•
        # è¿”å›é»˜è®¤ç»“æœ
        return {
            "filename": filename,
            "score": 75,
            "code_quality_score": 75,
            "security_score": 75,
            "business_score": 75,
            "performance_score": 75,
            "best_practices_score": 75,
            "issues": [
                {
                    "type": "warning",
                    "title": "è§£æå¤±è´¥",
                    "description": f"LLM å“åº”è§£æå¤±è´¥: {str(e)}",
                    "severity": "warning",
                    "category": "other",
                    "suggestion": "è¯·æ£€æŸ¥ LLM è¾“å‡ºæ ¼å¼",
                }
            ],
            "positive_points": ["æ–‡ä»¶å·²å®¡æŸ¥"],
            "summary": f"æ–‡ä»¶ {filename} å®¡æŸ¥å®Œæˆï¼ˆè§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤ç»“æœï¼‰",
        }


def _fix_json_format(json_str: str) -> str:
    """ä¿®å¤å¸¸è§çš„ JSON æ ¼å¼é—®é¢˜"""
    import re

    # ç§»é™¤å¯èƒ½çš„ markdown æ ‡è®°
    json_str = re.sub(r'^```json\s*', '', json_str)
    json_str = re.sub(r'\s*```$', '', json_str)
    json_str = re.sub(r'^```\s*', '', json_str)

    # ä¿®å¤å¸¸è§çš„ JSON æ ¼å¼é—®é¢˜
    # 1. ä¿®å¤ç¼ºå°‘é€—å·çš„é—®é¢˜ - æ›´ç²¾ç¡®çš„æ¨¡å¼
    # åœ¨å­—ç¬¦ä¸²å€¼åé¢ç¼ºå°‘é€—å·
    json_str = re.sub(r'"\s*\n\s*"', '",\n    "', json_str)
    # åœ¨æ•°å­—å€¼åé¢ç¼ºå°‘é€—å·
    json_str = re.sub(r'(\d+)\s*\n\s*"', r'\1,\n    "', json_str)
    # åœ¨å¸ƒå°”å€¼åé¢ç¼ºå°‘é€—å·
    json_str = re.sub(r'(true|false)\s*\n\s*"', r'\1,\n    "', json_str)
    # åœ¨æ•°ç»„åé¢ç¼ºå°‘é€—å·
    json_str = re.sub(r']\s*\n\s*"', '],\n    "', json_str)
    # åœ¨å¯¹è±¡åé¢ç¼ºå°‘é€—å·
    json_str = re.sub(r'}\s*\n\s*"', '},\n    "', json_str)

    # 2. ä¿®å¤å¤šä½™çš„é€—å·
    json_str = re.sub(r',\s*}', '}', json_str)
    json_str = re.sub(r',\s*]', ']', json_str)

    # 3. ä¿®å¤ä¸å®Œæ•´çš„ JSONï¼ˆå¦‚æœä»¥é€—å·ç»“å°¾ï¼Œå°è¯•è¡¥å…¨ï¼‰
    json_str = json_str.strip()
    if json_str.endswith(','):
        json_str = json_str[:-1]

    # 4. å¦‚æœ JSON ä¸å®Œæ•´ï¼Œå°è¯•è¡¥å…¨
    if json_str.count('{') > json_str.count('}'):
        json_str += '}' * (json_str.count('{') - json_str.count('}'))
    if json_str.count('[') > json_str.count(']'):
        json_str += ']' * (json_str.count('[') - json_str.count(']'))

    return json_str


def _extract_info_with_regex(response: str, filename: str) -> Dict[str, Any]:
    """ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ä»å“åº”ä¸­æå–å…³é”®ä¿¡æ¯ï¼Œä½œä¸º JSON è§£æå¤±è´¥çš„å¤‡ç”¨æ–¹æ¡ˆ"""
    import re

    result = {
        "filename": filename,
        "overall_score": 75,
        "code_quality_score": 75,
        "security_score": 75,
        "business_score": 75,
        "performance_score": 75,
        "best_practices_score": 75,
        "issues": [],
        "positive_points": [],
        "summary": f"æ–‡ä»¶ {filename} å®¡æŸ¥å®Œæˆï¼ˆä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è§£æï¼‰"
    }

    try:
        # æå–è¯„åˆ†
        score_patterns = [
            (r'"overall_score":\s*(\d+)', 'overall_score'),
            (r'"code_quality_score":\s*(\d+)', 'code_quality_score'),
            (r'"security_score":\s*(\d+)', 'security_score'),
            (r'"business_score":\s*(\d+)', 'business_score'),
            (r'"performance_score":\s*(\d+)', 'performance_score'),
            (r'"best_practices_score":\s*(\d+)', 'best_practices_score'),
        ]

        for pattern, key in score_patterns:
            match = re.search(pattern, response)
            if match:
                result[key] = int(match.group(1))

        # æå–æ€»ç»“
        summary_match = re.search(r'"summary":\s*"([^"]*)"', response)
        if summary_match:
            result["summary"] = summary_match.group(1)

        # æå–é—®é¢˜ï¼ˆç®€åŒ–ç‰ˆï¼‰
        issues = []
        issue_pattern = r'"title":\s*"([^"]*)".*?"description":\s*"([^"]*)"'
        issue_matches = re.findall(issue_pattern, response, re.DOTALL)

        for title, description in issue_matches:
            issues.append({
                "type": "info",
                "title": title,
                "description": description,
                "severity": "info",
                "category": "other",
                "suggestion": ""
            })

        result["issues"] = issues

        # æå–ç§¯æç‚¹
        positive_pattern = r'"positive_points":\s*\[(.*?)\]'
        positive_match = re.search(positive_pattern, response, re.DOTALL)
        if positive_match:
            positive_content = positive_match.group(1)
            positive_points = re.findall(r'"([^"]*)"', positive_content)
            result["positive_points"] = positive_points

    except Exception as e:
        logger.warning(f"æ­£åˆ™è¡¨è¾¾å¼æå–ä¹Ÿå¤±è´¥: {e}")

    return result


def _safe_get_score(score: Any) -> int:
    """å®‰å…¨åœ°è·å–è¯„åˆ†"""
    try:
        if isinstance(score, (int, float)):
            return max(0, min(100, int(score)))
        elif isinstance(score, str):
            return max(0, min(100, int(float(score))))
        else:
            return 80
    except (ValueError, TypeError):
        return 80


def _calculate_overall_scores(file_reviews: List[Dict[str, Any]]) -> Dict[str, Any]:
    """è®¡ç®—æ€»ä½“è¯„åˆ†"""
    if not file_reviews:
        return {
            "overall_score": 100,
            "code_quality_score": 100,
            "security_score": 100,
            "business_score": 100,
            "summary": "æ²¡æœ‰æ–‡ä»¶éœ€è¦å®¡æŸ¥",
            "standards_passed": 0,
            "standards_failed": 0,
            "standards_total": 0,
        }

    # è®¡ç®—å„ç»´åº¦å¹³å‡åˆ†ï¼ˆä½¿ç”¨å®‰å…¨çš„è¯„åˆ†è·å–ï¼‰
    total_files = len(file_reviews)

    avg_code_quality = (
            sum(_safe_get_score(fr.get("code_quality_score", 80)) for fr in file_reviews)
            / total_files
    )
    avg_security = (
            sum(_safe_get_score(fr.get("security_score", 80)) for fr in file_reviews)
            / total_files
    )
    avg_business = (
            sum(_safe_get_score(fr.get("business_score", 80)) for fr in file_reviews)
            / total_files
    )
    avg_performance = (
            sum(_safe_get_score(fr.get("performance_score", 80)) for fr in file_reviews)
            / total_files
    )
    avg_best_practices = (
            sum(_safe_get_score(fr.get("best_practices_score", 80)) for fr in file_reviews)
            / total_files
    )

    # è®¡ç®—æ€»ä½“è¯„åˆ†ï¼ˆåŠ æƒå¹³å‡ï¼‰
    overall_score = (
            avg_code_quality * 0.25
            + avg_security * 0.25
            + avg_business * 0.25
            + avg_performance * 0.125
            + avg_best_practices * 0.125
    )

    # ç»Ÿè®¡é—®é¢˜æ•°é‡ï¼ˆä½¿ç”¨å®‰å…¨çš„è¯„åˆ†è·å–ï¼‰
    total_issues = sum(len(fr.get("issues", [])) for fr in file_reviews)
    high_score_files = sum(
        1 for fr in file_reviews if _safe_get_score(fr.get("score", 80)) >= 85
    )

    # ç”Ÿæˆæ€»ç»“
    summary = f"å®¡æŸ¥äº† {total_files} ä¸ªæ–‡ä»¶ï¼Œå‘ç° {total_issues} ä¸ªé—®é¢˜ï¼Œ{high_score_files} ä¸ªæ–‡ä»¶è´¨é‡ä¼˜ç§€"

    return {
        "overall_score": round(overall_score, 1),
        "code_quality_score": round(avg_code_quality, 1),
        "security_score": round(avg_security, 1),
        "business_score": round(avg_business, 1),
        "performance_score": round(avg_performance, 1),
        "best_practices_score": round(avg_best_practices, 1),
        "summary": summary,
        "standards_passed": max(0, total_files * 5 - total_issues),  # ä¼°ç®—
        "standards_failed": total_issues,
        "standards_total": total_files * 5,
    }


def _safe_get_user_login(pr_info: Union[PRInfo, Dict[str, Any]]) -> str:
    """å®‰å…¨åœ°è·å–ç”¨æˆ·ç™»å½•å"""
    try:
        if isinstance(pr_info, PRInfo):
            return pr_info.author.login
        elif isinstance(pr_info, dict):
            # å‘åå…¼å®¹æ—§çš„å­—å…¸æ ¼å¼
            user = pr_info.get("user", "")
            if isinstance(user, dict):
                return str(user.get("login", "unknown"))
            elif isinstance(user, str):
                return user
            else:
                return "unknown"
        else:
            return "unknown"
    except Exception as e:
        logger.warning(f"è·å–ç”¨æˆ·ç™»å½•åå¤±è´¥: {e}")
        return "unknown"


def _safe_get_string(data: Any, default: str = "") -> str:
    """å®‰å…¨åœ°è·å–å­—ç¬¦ä¸²å€¼"""
    if data is None:
        return default
    return str(data)


async def run_code_review_async(pr_info: Dict[str, Any]) -> Dict[str, Any]:
    """å¼‚æ­¥è¿è¡Œä»£ç å®¡æŸ¥

    Args:
        pr_info: PR ä¿¡æ¯ï¼ŒåŒ…å« repo å’Œ number

    Returns:
        å®¡æŸ¥ç»“æœ
    """
    # æ„é€ å·¥ä½œæµ
    graph = build_code_review_graph()

    # è§£æä½œè€…ä¿¡æ¯
    author_data = pr_info.get("author", {})
    if isinstance(author_data, dict):
        author = UserInfo(**author_data)
    else:
        author = UserInfo(login="unknown")

    # åˆ›å»ºPRä¿¡æ¯æ¨¡å‹
    pr_info_model = PRInfo(
        repo=pr_info["repo"],
        number=pr_info["number"],
        platform=pr_info.get("platform", "github"),
        author=author,
        title=pr_info.get("title", ""),
        body=pr_info.get("body", ""),
        head_sha=pr_info.get("head_sha", ""),
        base_sha=pr_info.get("base_sha", ""),
        repo_full_name=pr_info.get("repo_full_name", pr_info["repo"])
    )

    # åˆå§‹çŠ¶æ€
    initial_state = AgentState(
        pr_info=pr_info_model
    )

    # å¼‚æ­¥æ‰§è¡Œå›¾
    result = await graph.ainvoke(initial_state)

    # è½¬æ¢ç»“æœä¸ºå­—å…¸æ ¼å¼ä»¥ä¿æŒå‘åå…¼å®¹
    return _convert_state_to_dict(result)


def _convert_state_to_dict(state: Union[AgentState, Dict[str, Any]]) -> Dict[str, Any]:
    """å°†AgentStateæˆ–å­—å…¸çŠ¶æ€è½¬æ¢ä¸ºå­—å…¸æ ¼å¼ä»¥ä¿æŒå‘åå…¼å®¹"""
    # å¤„ç† LangGraph è¿”å›çš„ AddableValuesDict æˆ–å…¶ä»–å­—å…¸ç±»å‹
    if isinstance(state, dict):
        # å¦‚æœæ˜¯å­—å…¸ç±»å‹ï¼Œç›´æ¥ä½¿ç”¨
        file_reviews_data = state.get("file_reviews", [])
        enhanced_analysis_data = state.get("enhanced_analysis")
        pr_info_data = state.get("pr_info", {})
        files_data = state.get("files", [])
        file_contents_data = state.get("file_contents", {})
        overall_summary_data = state.get("overall_summary")
        db_record_id_data = state.get("db_record_id")
    else:
        # å¦‚æœæ˜¯ AgentState å¯¹è±¡
        file_reviews_data = state.file_reviews
        enhanced_analysis_data = state.enhanced_analysis
        pr_info_data = state.pr_info
        files_data = state.files
        file_contents_data = state.file_contents
        overall_summary_data = state.overall_summary
        db_record_id_data = state.db_record_id

    file_reviews = []
    for review in file_reviews_data:
        if isinstance(review, FileReviewInfo):
            file_reviews.append({
                "filename": review.filename,
                "score": review.score,
                "code_quality_score": review.code_quality_score,
                "security_score": review.security_score,
                "business_score": review.business_score,
                "performance_score": review.performance_score,
                "best_practices_score": review.best_practices_score,
                "issues": [issue.model_dump() for issue in review.issues],
                "positive_points": review.positive_points,
                "summary": review.summary,
            })
        else:
            file_reviews.append(review)

    # å¤„ç†å¢å¼ºåˆ†ææ•°æ®
    enhanced_analysis = None
    if enhanced_analysis_data:
        if hasattr(enhanced_analysis_data, 'model_dump'):
            enhanced_analysis = enhanced_analysis_data.model_dump()
        else:
            enhanced_analysis = enhanced_analysis_data

    # å¤„ç† PR ä¿¡æ¯æ•°æ®
    if hasattr(pr_info_data, 'model_dump'):
        pr_info_dict = pr_info_data.model_dump()
    else:
        pr_info_dict = pr_info_data

    # å¤„ç†æ–‡ä»¶æ•°æ®
    files_list = []
    for f in files_data:
        if hasattr(f, 'model_dump'):
            files_list.append(f.model_dump())
        else:
            files_list.append(f)

    return {
        "pr_info": pr_info_dict,
        "files": files_list,
        "file_contents": file_contents_data,
        "file_reviews": file_reviews,
        "overall_summary": overall_summary_data,
        "enhanced_analysis": enhanced_analysis,
        "db_record_id": db_record_id_data,
    }


def run_code_review(pr_info: Dict[str, Any]) -> Dict[str, Any]:
    """è¿è¡Œä»£ç å®¡æŸ¥ - åŒæ­¥åŒ…è£…å™¨

    Args:
        pr_info: PR ä¿¡æ¯ï¼ŒåŒ…å« repo å’Œ number

    Returns:
        å®¡æŸ¥ç»“æœ
    """
    import asyncio

    # è·å–æˆ–åˆ›å»ºäº‹ä»¶å¾ªç¯
    try:
        loop = asyncio.get_event_loop()
        if loop.is_running():
            # å¦‚æœäº‹ä»¶å¾ªç¯æ­£åœ¨è¿è¡Œï¼Œåˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯
            import concurrent.futures

            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(asyncio.run, run_code_review_async(pr_info))
                return future.result()
        else:
            # å¦‚æœäº‹ä»¶å¾ªç¯æ²¡æœ‰è¿è¡Œï¼Œç›´æ¥ä½¿ç”¨
            return loop.run_until_complete(run_code_review_async(pr_info))
    except RuntimeError:
        # å¦‚æœæ²¡æœ‰äº‹ä»¶å¾ªç¯ï¼Œåˆ›å»ºæ–°çš„
        return asyncio.run(run_code_review_async(pr_info))
